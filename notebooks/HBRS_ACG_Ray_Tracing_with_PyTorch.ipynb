{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "AZ0I2Mm5kE5P"
   },
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as tf\n",
    "import torch.linalg as la\n",
    "import numpy as np\n",
    "#import plotly.graph_objects as go\n",
    "import pyvista as pv\n",
    "\n",
    "#%pip list -v\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "log_level_debug = False\n",
    "log_level_info = True"
   ],
   "metadata": {
    "id": "bzowKooAnZuF"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# global PyTorch settings\n",
    "\n",
    "# disable gradient tracking not needed in this ray tracer to save compute\n",
    "torch.set_grad_enabled(False)\n"
   ],
   "metadata": {
    "id": "ia7TnKFzgALi"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# global PyVista settings\n",
    "\n",
    "# render on client-side instead of Jupyter server\n",
    "pv.set_jupyter_backend('client')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# check for Metal Performance Shaders in case of macOS just out of curiosity\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n"
   ],
   "metadata": {
    "id": "KD1vIlngcJ2c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device_str = \"cuda\"\n",
    "    device = torch.device(device_str)\n",
    "    print(f\"CUDA is available. Using first GPU.\")\n",
    "else:\n",
    "    device_str = \"cpu\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "print(f\"device={device}\")\n"
   ],
   "metadata": {
    "id": "PoesBXcpFc6x"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# offer custom utility functions\n",
    "\n",
    "def create_tensor(v):\n",
    "      return torch.tensor(v, dtype=torch.float, requires_grad=False)\n",
    "\n",
    "def create_tensor_on_device(v):\n",
    "      return torch.tensor(v, dtype=torch.float, requires_grad=False).to(device)\n",
    "\n",
    "def is_float_tensor(obj):\n",
    "    return isinstance(obj, torch.FloatTensor) or isinstance(obj, torch.cuda.FloatTensor)\n",
    "\n",
    "def is_float_tensor_on_device(obj):\n",
    "    # obj.device.type is a str\n",
    "    return is_float_tensor(obj) and (device_str == obj.device.type)\n",
    "\n",
    "def is_long_tensor(obj):\n",
    "    return isinstance(obj, torch.LongTensor) or isinstance(obj, torch.cuda.LongTensor)\n",
    "\n",
    "def normalize_vector_custom(v):\n",
    "    return v / torch.max(torch.norm(v), torch.tensor(1e-12, dtype=torch.float))\n",
    "\n",
    "def normalize_vector(v):\n",
    "    return tf.normalize(v, dim=0)\n",
    "\n",
    "def mean_ignoring_zero(t):\n",
    "    mask = t != 0.0\n",
    "    t_mean = (t * mask).sum(dim=0) / mask.sum(dim=0)\n",
    "    return t_mean\n",
    "\n",
    "def see(name, value, critical=True):\n",
    "    if log_level_debug or (critical and log_level_info):\n",
    "        if is_float_tensor(value):\n",
    "            if len(value.shape) == 0:\n",
    "                # scalar\n",
    "                print(f\"{name}={value}\")\n",
    "            elif len(value.shape) == 1:\n",
    "                if value.shape[0] >= 2:\n",
    "                    # vector\n",
    "                    print(f\"torch.norm({name})={torch.norm(value)}\")\n",
    "                print(f\"{name}.shape={value.shape}\")\n",
    "                print(f\"{name}={value}\")\n",
    "            else:\n",
    "               # matrix or higher-dimensional tensor\n",
    "               print(f\"{name}.shape={value.shape}\")\n",
    "               print(f\"{name}=\\n{value}\")\n",
    "        else:\n",
    "            print(f\"{name}={value}\")\n",
    "\n",
    "def see_more(name, value, critical=True):\n",
    "    if log_level_debug or (critical and log_level_info):\n",
    "        see(name, value, critical)\n",
    "        if len(value.shape) > 0:\n",
    "            print(f\"{name}.min()={value.min()}\")\n",
    "            print(f\"{name}.mean()={value.mean(dtype=torch.float)}\")\n",
    "            print(f\"mean_ignoring_zero({name})={mean_ignoring_zero(value)}\")\n",
    "            #print(f\"{name}.mode()={value.mode()}\")\n",
    "            print(f\"{name}.median()={value.median()}\")\n",
    "            print(f\"{name}.max()={value.max()}\")\n"
   ],
   "metadata": {
    "id": "eB0D8O9wxbsA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# define constants\n",
    "\n",
    "minus_one_dot_zero = create_tensor_on_device(-1.0)\n",
    "minus_zero_dot_five = create_tensor_on_device(-0.5)\n",
    "zero_dot_zero = create_tensor_on_device(0.0)\n",
    "one_dot_zero = create_tensor_on_device(1.0)\n",
    "two_dot_zero = create_tensor_on_device(2.0)\n",
    "four_dot_zero = create_tensor_on_device(4.0)\n",
    "\n",
    "zero_vector_float = create_tensor_on_device([0.0, 0.0, 0.0])\n",
    "zero_vector_int = torch.tensor([0.0, 0.0, 0.0], dtype=torch.int, requires_grad=False)\n"
   ],
   "metadata": {
    "id": "4D2J_iTflS6X"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# define spheres\n",
    "\n",
    "# each sphere is defined by its center in camera system coordinates and its radius\n",
    "\n",
    "def create_spheres_1():\n",
    "    spheres_center_py = [[-1.0, 0.0, 8.0], [2.0, -2.0, 12.0], [0.0, 0.0, 20.0], [-8.0, 0.0, 10.0]]\n",
    "    spheres_center_pt = torch.tensor(spheres_center_py, dtype=torch.float, requires_grad=False)\n",
    "    n_spheres = spheres_center_pt.shape[0]\n",
    "    spheres_radius_py = [1.0, 5.0, 10.0, 2.0]\n",
    "    spheres_radius_pt = torch.tensor(spheres_radius_py, dtype=torch.float, requires_grad=False)\n",
    "    spheres_rgb_py = [[150, 90, 200], [255, 144, 0], [255, 255, 255], [255, 0, 0]]\n",
    "    spheres_rgb_pt = torch.tensor(spheres_rgb_py, dtype=torch.int, requires_grad=False)\n",
    "    assert spheres_center_pt.shape == (n_spheres, 3)\n",
    "    assert spheres_radius_pt.shape == (n_spheres,)\n",
    "    assert spheres_rgb_pt.shape == (n_spheres, 3)\n",
    "    return spheres_center_pt, spheres_radius_pt, spheres_rgb_pt\n",
    "\n",
    "spheres_center, spheres_radius, spheres_rgb = create_spheres_1()\n",
    "spheres_center = spheres_center.to(device)\n",
    "spheres_radius = spheres_radius.to(device)\n",
    "spheres_rgb = spheres_rgb.to(device)\n",
    "\n",
    "see(\"spheres_center\", spheres_center)\n",
    "assert is_float_tensor_on_device(spheres_center)\n",
    "\n",
    "see(\"spheres_radius\", spheres_radius)\n",
    "assert is_float_tensor_on_device(spheres_radius)\n",
    "\n",
    "see(\"spheres_rgb\", spheres_rgb)\n",
    "\n",
    "n_spheres = spheres_center.shape[0]\n",
    "assert n_spheres == 4"
   ],
   "metadata": {
    "id": "VkgtmBagh4vm"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define the camera\n",
    "\n",
    "near = create_tensor_on_device(0.1)\n",
    "far = create_tensor_on_device(100.0)\n",
    "\n",
    "resx_float_py = 1920.0\n",
    "resy_float_py = 1080.0\n",
    "resx_int_py = int(resx_float_py)\n",
    "resy_int_py = int(resy_float_py)\n",
    "resx = create_tensor_on_device(resx_float_py)\n",
    "resy = create_tensor_on_device(resy_float_py)\n",
    "\n",
    "middle_pixel_index = int((resy_int_py / 2) * resx_int_py + (resy_int_py / 2))\n",
    "\n",
    "n_pixels = int((resx * resy).item())\n",
    "see(\"n_pixels\", n_pixels)\n",
    "assert isinstance(n_pixels, int)\n",
    "\n",
    "resx_half = resx / two_dot_zero\n",
    "resy_half = resy / two_dot_zero\n",
    "\n",
    "see(\"far\", far)\n",
    "see(\"near\", near)\n",
    "see(\"resx\", resx)\n",
    "see(\"resy\", resy)\n",
    "see(\"resx_half\", resx_half)\n",
    "see(\"resy_half\", resy_half)\n",
    "\n",
    "# position of the eye point\n",
    "#eye = create_tensor_on_device([0.22, 0.0, -0.44])\n",
    "eye = create_tensor_on_device([0.0, 0.0, 0.0])\n",
    "see(\"eye\", eye)\n",
    "see(\"eye.type\", eye.type())\n",
    "see(\"eye.device\", eye.device)\n",
    "assert is_float_tensor_on_device(eye)\n",
    "\n",
    "# upright direction of the camera orientation\n",
    "up = create_tensor_on_device([0.0, 1.0, 0.0])\n",
    "up = tf.normalize(up, dim=0)\n",
    "assert torch.allclose(up, normalize_vector_custom(up))\n",
    "assert torch.allclose(up, normalize_vector(up))\n",
    "see(\"up\", up)\n",
    "assert is_float_tensor_on_device(up)\n",
    "\n",
    "# look is center of image plane\n",
    "#look = create_tensor_on_device([1.0, 0.0, 2.0])\n",
    "look = create_tensor_on_device([0.0, 0.0, 1.5])\n",
    "see(\"look\", look)\n",
    "assert is_float_tensor_on_device(look)\n",
    "\n",
    "gaze = look - eye\n",
    "assert is_float_tensor_on_device(gaze)\n",
    "\n",
    "# distance from the eye to center of image plane\n",
    "distance_intrinsic = torch.norm(gaze)\n",
    "see(\"distance_intrinsic\", distance_intrinsic)\n",
    "assert is_float_tensor_on_device(distance_intrinsic)\n",
    "\n",
    "# direction from eye towards center of image plane\n",
    "gaze_unit = tf.normalize(gaze, dim=0)\n",
    "see(\"gaze\", gaze)\n",
    "see(\"gaze_unit\", gaze_unit)\n",
    "assert torch.isclose(torch.norm(gaze_unit), torch.tensor(1., dtype=torch.float, requires_grad=False))\n",
    "assert is_float_tensor_on_device(gaze_unit)\n",
    "\n",
    "scrnx_unit = la.cross(up, gaze_unit, dim=0)\n",
    "scrnx_unit = tf.normalize(scrnx_unit, dim=0)\n",
    "assert torch.isclose(torch.norm(scrnx_unit), torch.tensor(1., dtype=torch.float, requires_grad=False))\n",
    "# !? hack to get numerically perfect scrnx in special case\n",
    "scrnx_unit_perfect = create_tensor_on_device([1.,0.,0.])\n",
    "if torch.allclose(scrnx_unit, scrnx_unit_perfect):\n",
    "    print(\"Using perfect scrnx_unit.\")\n",
    "    scrnx_unit = scrnx_unit_perfect\n",
    "see(\"scrnx_unit\", scrnx_unit)\n",
    "assert is_float_tensor_on_device(scrnx_unit)\n",
    "\n",
    "scrny_unit = la.cross(gaze_unit, scrnx_unit, dim=0)\n",
    "scrny_unit = tf.normalize(scrny_unit, dim=0)\n",
    "assert torch.isclose(torch.norm(scrny_unit), torch.tensor(1., dtype=torch.float, requires_grad=False))\n",
    "# !? hack to get numerically perfect scrny in special case\n",
    "scrny_unit_perfect = create_tensor_on_device([0.,1.,0.])\n",
    "if torch.allclose(scrny_unit, scrny_unit_perfect):\n",
    "    print(\"Using perfect scrny_unit.\")\n",
    "    scrny_unit = scrny_unit_perfect\n",
    "see(\"scrny_unit\", scrny_unit)\n",
    "assert is_float_tensor_on_device(scrny_unit)\n",
    "\n",
    "# !? note that we compute scrnz so it points towards the eye\n",
    "# i.e. it is the most reasonable normal of the image plane\n",
    "scrnz_unit = la.cross(scrnx_unit, scrny_unit, dim=0)\n",
    "scrnz_unit = tf.normalize(scrnz_unit, dim=0)\n",
    "# !? hack to get numerically perfect scrnz in special case\n",
    "scrnz_unit_perfect = create_tensor_on_device([0.,0.,1.])\n",
    "if torch.allclose(scrnz_unit, scrnz_unit_perfect):\n",
    "    print(\"Using perfect scrnz_unit.\")\n",
    "    scrnz_unit = scrnz_unit_perfect\n",
    "see(\"scrnz_unit\", scrnz_unit)\n",
    "assert is_float_tensor_on_device(scrnz_unit)\n",
    "\n",
    "# note that fovx is actually representing half of the horizontal field of view\n",
    "fovx_degrees = create_tensor_on_device(50.0)\n",
    "see(\"fovx_degrees\", fovx_degrees)\n",
    "assert is_float_tensor_on_device(fovx_degrees)\n",
    "\n",
    "fovx_radians = torch.deg2rad(fovx_degrees)\n",
    "see(\"fovx_radians\", fovx_radians)\n",
    "assert is_float_tensor_on_device(fovx_radians)\n",
    "\n",
    "# note that fovy is actually representing half of the vertical field of view\n",
    "fovy_degrees = fovx_degrees / (resx / resy)\n",
    "# resx and resy are already tensors thus no neeed to wrap resx / resy\n",
    "#fovy_degrees = fovx_degrees / torch.tensor(resx / resy, dtype=torch.float)\n",
    "see(\"fovy_degrees\", fovy_degrees)\n",
    "assert is_float_tensor_on_device(fovy_degrees)\n",
    "\n",
    "# override fovy to optimize magnitude of a pixel in y direction\n",
    "fovy_degrees = create_tensor_on_device(33.83)\n",
    "see(\"fovy_degrees\", fovy_degrees)\n",
    "assert is_float_tensor_on_device(fovy_degrees)\n",
    "\n",
    "fovy_radians = torch.deg2rad(fovy_degrees)\n",
    "see(\"fovy_radians\", fovy_radians)\n",
    "assert is_float_tensor_on_device(fovy_radians)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# compute size of a pixel and scale scrnx and scrny accordingly\n",
    "\n",
    "def compute_magnitude_of_a_pixel(distance, fov_radians, res, two_dot_zero):\n",
    "     mag = torch.abs(two_dot_zero * distance * (torch.tan(fov_radians) / res))\n",
    "     assert is_float_tensor_on_device(mag)\n",
    "     return mag\n",
    "\n",
    "# magx is the length aka. magnitude of a pixel in direction scrnx\n",
    "magx = compute_magnitude_of_a_pixel(distance_intrinsic, fovx_radians, resx, two_dot_zero)\n",
    "scrnx_scaled = scrnx_unit * magx\n",
    "# scrnx is now 1 pixel long in horizontal direction of the image plane\n",
    "see(\"scrnx_scaled\", scrnx_scaled)\n",
    "assert torch.isclose(torch.norm(scrnx_scaled), magx)\n",
    "assert is_float_tensor_on_device(magx)\n",
    "assert is_float_tensor_on_device(scrnx_scaled)\n",
    "\n",
    "# magy is the length aka. magnitude of a pixel in direction scrny\n",
    "magy = compute_magnitude_of_a_pixel(distance_intrinsic, fovy_radians, resy, two_dot_zero)\n",
    "scrny_scaled = scrny_unit * magy\n",
    "# scrny is now 1 pixel long in vertical direction of the image plane\n",
    "see(\"scrny_scaled\", scrny_scaled)\n",
    "assert torch.isclose(torch.norm(scrny_scaled), magy)\n",
    "assert is_float_tensor_on_device(magy)\n",
    "assert is_float_tensor_on_device(scrny_scaled)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# compute position of the pixel in the upper left corner of the image plane relative to the eye\n",
    "\n",
    "def scale_scrn_vectors(scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero):\n",
    "    ox = scrnx * ((resx / two_dot_zero) - resx_off)\n",
    "    oy = scrny * ((resy / two_dot_zero) - resy_off)\n",
    "    return ox, oy\n",
    "\n",
    "def compute_relative_position_of_pixel_upper_left(gaze, scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero):\n",
    "     # we assume that gaze is pointing exactly to the middle of the image plane\n",
    "     # i.e. gaze is pointing at the center of the point between the four mid-most pixels\n",
    "     ox, oy = scale_scrn_vectors(scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero)\n",
    "     px_ul_pos = gaze - ox + oy\n",
    "     assert is_float_tensor_on_device(px_ul_pos)\n",
    "     return px_ul_pos\n",
    "\n",
    "# we also compute these relative positions of some other pixels just for sanity checks\n",
    "\n",
    "def compute_relative_position_of_pixel_lower_left(gaze, scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero):\n",
    "     # we assume that gaze is pointing exactly to the middle of the image plane\n",
    "     # i.e. gaze is pointing at the center of the point between the four mid-most pixels\n",
    "     ox, oy = scale_scrn_vectors(scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero)\n",
    "     px_ll_pos = gaze - ox - oy\n",
    "     assert is_float_tensor_on_device(px_ll_pos)\n",
    "     return px_ll_pos\n",
    "\n",
    "def compute_relative_position_of_pixel_upper_right(gaze, scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero):\n",
    "     # we assume that gaze is pointing exactly to the middle of the image plane\n",
    "     # i.e. gaze is pointing at the center of the point between the four mid-most pixels\n",
    "     ox, oy = scale_scrn_vectors(scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero)\n",
    "     px_ur_pos = gaze + ox + oy\n",
    "     assert is_float_tensor_on_device(px_ur_pos)\n",
    "     return px_ur_pos\n",
    "\n",
    "def compute_relative_position_of_pixel_lower_right(gaze, scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero):\n",
    "     # we assume that gaze is pointing exactly to the middle of the image plane\n",
    "     # i.e. gaze is pointing at the center of the point between the four mid-most pixels\n",
    "     ox, oy = scale_scrn_vectors(scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero)\n",
    "     px_lr_pos = gaze + ox - oy\n",
    "     assert is_float_tensor_on_device(px_lr_pos)\n",
    "     return px_lr_pos\n",
    "\n",
    "# factors to ensure computed positions are the middle of pixels\n",
    "resx_off = create_tensor_on_device(0.5)\n",
    "resy_off = create_tensor_on_device(0.5)\n",
    "assert is_float_tensor_on_device(resx_off)\n",
    "assert is_float_tensor_on_device(resy_off)\n",
    "\n",
    "px_ul = compute_relative_position_of_pixel_upper_left(gaze, scrnx_scaled, resx, resx_off, scrny_scaled, resy, resy_off, two_dot_zero)\n",
    "see(\"px_ul\", px_ul)\n",
    "\n",
    "px_ll = compute_relative_position_of_pixel_lower_left(gaze, scrnx_scaled, resx, resx_off, scrny_scaled, resy, resy_off, two_dot_zero)\n",
    "see(\"px_ll\", px_ll)\n",
    "\n",
    "px_ur = compute_relative_position_of_pixel_upper_right(gaze, scrnx_scaled, resx, resx_off, scrny_scaled, resy, resy_off, two_dot_zero)\n",
    "see(\"px_ur\", px_ur)\n",
    "\n",
    "px_lr = compute_relative_position_of_pixel_lower_right(gaze, scrnx_scaled, resx, resx_off, scrny_scaled, resy, resy_off, two_dot_zero)\n",
    "see(\"px_lr\", px_lr)\n",
    "\n",
    "distance_px_ul_px_ur = torch.norm(px_ul - px_ur)\n",
    "see(\"distance_px_ul_px_ur\", distance_px_ul_px_ur)\n",
    "\n",
    "# note that a pixel position vector points to the middle of a pixel\n",
    "# therefore when calculating a width of the image plane\n",
    "# we count two times half a pixel less\n",
    "# which is represented here by subtracting resx_off twice before scaling\n",
    "distance_px_ul_px_ur_anticipated = (resx - resx_off - resx_off) * magx\n",
    "see(\"distance_px_ul_px_ur_anticipated\", distance_px_ul_px_ur_anticipated, False)\n",
    "\n",
    "assert torch.isclose(distance_px_ul_px_ur, distance_px_ul_px_ur_anticipated)\n",
    "\n",
    "distance_px_ul_px_ll = torch.norm(px_ul - px_ll)\n",
    "see(\"distance_px_ul_px_ll\", distance_px_ul_px_ll, False)\n",
    "\n",
    "# note that a pixel position vector points to the middle of a pixel\n",
    "# therefore when calculating a height of the image plane\n",
    "# we count two times half a pixel less\n",
    "# which is represented here by subtracting resy_off twice before scaling\n",
    "distance_px_ul_px_ll_anticipated = (resy - resy_off - resy_off) * magy\n",
    "see(\"distance_px_ul_px_ll_anticipated\", distance_px_ul_px_ll_anticipated, False)\n",
    "\n",
    "assert torch.isclose(distance_px_ul_px_ll, distance_px_ul_px_ll_anticipated)\n",
    "\n",
    "distance_aspect_ratio = distance_px_ul_px_ur / distance_px_ul_px_ll\n",
    "see(\"distance_aspect_ratio\", distance_aspect_ratio, False)\n",
    "\n",
    "distance_aspect_ratio_anticipated = distance_px_ul_px_ur / distance_px_ul_px_ll\n",
    "see(\"distance_aspect_ratio_anticipated\", distance_aspect_ratio_anticipated, False)\n",
    "\n",
    "if fovy_degrees.item() == 33.83:\n",
    "    distance_aspect_ratio_anticipated_also = resx / resy\n",
    "    see(\"distance_aspect_ratio_anticipated_also\", distance_aspect_ratio_anticipated_also, False)\n",
    "\n",
    "    assert torch.isclose(distance_aspect_ratio, distance_aspect_ratio_anticipated_also, rtol=1e-03)\n",
    "\n",
    "    distance_aspect_ratio_anticipated_moreover = create_tensor_on_device(16.0 / 9.0)\n",
    "    see(\"distance_aspect_ratio_anticipated_moreover\", distance_aspect_ratio_anticipated_moreover, False)\n",
    "\n",
    "    assert torch.isclose(distance_aspect_ratio, distance_aspect_ratio_anticipated_moreover, rtol=1e-03)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# compute the grid of vectors that form the image plane\n",
    "\n",
    "# each pixel will be represented by a vector pointing to its middle\n",
    "\n",
    "# create a vector per pixel on the image plane\n",
    "# with each pixel 1.0 wide and 1.0 high\n",
    "# and with the center of the image plane is the origin\n",
    "\n",
    "img_grid_original_firstx = minus_one_dot_zero * ((resx / two_dot_zero) - resx_off)\n",
    "img_grid_original_lastx = ((resx / two_dot_zero) - resx_off + one_dot_zero)\n",
    "img_grid_original_firsty =((resy / two_dot_zero) - resy_off)\n",
    "img_grid_original_lasty = minus_one_dot_zero * ((resy / two_dot_zero) - resy_off + one_dot_zero)\n",
    "\n",
    "img_grid_original = torch.cartesian_prod(torch.arange(start=img_grid_original_firstx, end=img_grid_original_lastx, step=1.0, dtype=torch.float, requires_grad=False),\n",
    "                                         torch.arange(start=img_grid_original_firsty, end=img_grid_original_lasty, step=-1.0, dtype=torch.float, requires_grad=False),\n",
    "                                         torch.tensor([0.0], dtype=torch.float, requires_grad=False))\n",
    "see(\"img_grid_original\", img_grid_original)\n",
    "img_grid_original = img_grid_original.to(device)\n",
    "assert is_float_tensor_on_device(img_grid_original)\n",
    "\n",
    "n_pixels_anticipated = img_grid_original.shape[0]\n",
    "assert isinstance(n_pixels_anticipated, int)\n",
    "assert n_pixels == n_pixels_anticipated\n",
    "\n",
    "# scale the image plane using the width of a pixel and the height of a pixel\n",
    "\n",
    "identity_matrix_3_by_3 = torch.eye(3, dtype=torch.float, requires_grad=False).to(device)\n",
    "img_grid_scaling_matrix = identity_matrix_3_by_3 * create_tensor_on_device([magx, magy, 0.0])\n",
    "see(\"img_grid_scaling_matrix\", img_grid_scaling_matrix, False)\n",
    "assert is_float_tensor_on_device(img_grid_scaling_matrix)\n",
    "\n",
    "img_grid_scaled = torch.matmul(img_grid_original, img_grid_scaling_matrix)\n",
    "see(\"img_grid_scaled\", img_grid_scaled, False)\n",
    "assert is_float_tensor_on_device(img_grid_scaled)\n",
    "\n",
    "distance_px_ul_px_lr = torch.norm(px_ul - px_lr)\n",
    "see(\"distance_px_ul_px_lr\", distance_px_ul_px_lr, False)\n",
    "\n",
    "distance_px_ul_px_lr_after_scaling = torch.norm(img_grid_scaled[n_pixels - 1] - img_grid_scaled[0])\n",
    "see(\"distance_px_ul_px_lr_after_scaling\", distance_px_ul_px_lr_after_scaling, False)\n",
    "\n",
    "assert is_float_tensor_on_device(distance_px_ul_px_lr_after_scaling)\n",
    "assert torch.isclose(distance_px_ul_px_lr, distance_px_ul_px_lr_after_scaling)\n",
    "\n",
    "# rotate the image plane around the origin\n",
    "\n",
    "scrnz_unit_neg = normalize_vector(minus_one_dot_zero * scrnz_unit)\n",
    "assert is_float_tensor_on_device(scrnz_unit_neg)\n",
    "\n",
    "img_grid_rotation_matrix = torch.stack([scrnx_unit, scrny_unit, scrnz_unit_neg], dim=1)\n",
    "#img_grid_rotation_matrix = torch.stack([scrnx_unit, scrny_unit, scrnz_unit], dim=1)\n",
    "assert is_float_tensor_on_device(img_grid_rotation_matrix)\n",
    "see(\"img_grid_rotation_matrix\", img_grid_rotation_matrix, False)\n",
    "\n",
    "img_grid_rotated_px_ul = img_grid_rotation_matrix @ img_grid_scaled[0]\n",
    "see(\"img_grid_rotated_px_ul\", img_grid_rotated_px_ul, False)\n",
    "\n",
    "img_grid_rotated_px_lr = img_grid_rotation_matrix @ img_grid_scaled[n_pixels - 1]\n",
    "see(\"img_grid_rotated_px_lr\", img_grid_rotated_px_lr, False)\n",
    "\n",
    "img_grid_rotated = torch.matmul(img_grid_scaled, img_grid_rotation_matrix)\n",
    "see(\"img_grid_rotated\", img_grid_rotated, False)\n",
    "\n",
    "distance_px_ul_px_lr_after_rotation = torch.norm(img_grid_rotated[n_pixels - 1] - img_grid_rotated[0])\n",
    "see(\"distance_px_ul_px_lr_after_rotation\", distance_px_ul_px_lr_after_rotation, False)\n",
    "\n",
    "assert torch.isclose(distance_px_ul_px_lr_after_scaling, distance_px_ul_px_lr_after_rotation)\n",
    "assert torch.isclose(distance_px_ul_px_lr, distance_px_ul_px_lr_after_rotation)\n",
    "\n",
    "# then we translate the image plane into position\n",
    "\n",
    "# translage by look\n",
    "\n",
    "img_grid_translated_by_look = img_grid_rotated + look\n",
    "see(\"img_grid_translated_by_look\", img_grid_translated_by_look, False)\n",
    "\n",
    "distance_px_ul_px_lr_after_translation_by_look = torch.norm(img_grid_translated_by_look[n_pixels - 1] - img_grid_translated_by_look[0])\n",
    "see(\"distance_px_ul_px_lr_after_translation_by_look\", distance_px_ul_px_lr_after_translation_by_look, False)\n",
    "\n",
    "assert torch.isclose(distance_px_ul_px_lr_after_scaling, distance_px_ul_px_lr_after_translation_by_look)\n",
    "assert torch.isclose(distance_px_ul_px_lr_after_scaling, distance_px_ul_px_lr_after_translation_by_look)\n",
    "assert torch.isclose(distance_px_ul_px_lr, distance_px_ul_px_lr_after_translation_by_look)\n",
    "\n",
    "# translate by eye and gaze\n",
    "\n",
    "img_grid_translated_by_eye_and_gaze = img_grid_rotated + eye + gaze\n",
    "see(\"img_grid_translated_by_eye_and_gaze\", img_grid_translated_by_eye_and_gaze, False)\n",
    "\n",
    "distance_px_ul_px_lr_after_translation_by_eye_and_gaze = torch.norm(img_grid_translated_by_eye_and_gaze[n_pixels - 1] - img_grid_translated_by_eye_and_gaze[0])\n",
    "see(\"distance_px_ul_px_lr_after_translation_by_eye_and_gaze\", distance_px_ul_px_lr_after_translation_by_eye_and_gaze, False)\n",
    "\n",
    "assert torch.isclose(distance_px_ul_px_lr_after_scaling, distance_px_ul_px_lr_after_translation_by_eye_and_gaze)\n",
    "assert torch.isclose(distance_px_ul_px_lr_after_scaling, distance_px_ul_px_lr_after_translation_by_eye_and_gaze)\n",
    "assert torch.isclose(distance_px_ul_px_lr, distance_px_ul_px_lr_after_translation_by_eye_and_gaze)\n",
    "\n",
    "# as expected these translations result in the same grid\n",
    "\n",
    "assert torch.allclose(img_grid_translated_by_look, img_grid_translated_by_eye_and_gaze, rtol=0.1)\n",
    "\n",
    "img_grid = img_grid_translated_by_look\n",
    "assert is_float_tensor_on_device(img_grid)\n",
    "see(\"img_grid\", img_grid)\n"
   ],
   "metadata": {
    "id": "6BI8OtiFfFsZ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# compute a direction vector per primary ray\n",
    "\n",
    "# since we have the image grid\n",
    "# this is now just one parallelized operation\n",
    "\n",
    "if log_level_debug:\n",
    "    print(f\"eye={eye}\")\n",
    "    print(f\"look={look}\")\n",
    "    print(f\"gaze={gaze}\")\n",
    "    print(f\"up={up}\")\n",
    "\n",
    "    print(f\"scrnx_unit={scrnx_unit}\")\n",
    "    print(f\"scrny_unit={scrny_unit}\")\n",
    "    print(f\"scrnz_unit={scrnz_unit}\")\n",
    "\n",
    "    print(f\"scrnx_unit dot scrny_unit={torch.dot(scrnx_unit, scrny_unit)}\")\n",
    "    print(f\"scrnx_unit dot scrnz_unit={torch.dot(scrnx_unit, scrnz_unit)}\")\n",
    "    print(f\"scrny_unit dot scrnz_unit={torch.dot(scrny_unit, scrnz_unit)}\")\n",
    "\n",
    "    print(f\"scrnx_scaled dot scrny_scaled={torch.dot(scrnx_scaled, scrny_scaled)}\")\n",
    "    print(f\"scrnx_scaled dot scrnz_unit={torch.dot(scrnx_scaled, scrnz_unit)}\")\n",
    "    print(f\"scrny_scaled dot scrnz_unit={torch.dot(scrny_scaled, scrnz_unit)}\")\n",
    "\n",
    "    print(f\"scrnx_unit dot gaze={torch.dot(scrnx_unit, gaze)}\")\n",
    "    print(f\"scrny_unit dot gaze={torch.dot(scrny_unit, gaze)}\")\n",
    "\n",
    "    print(f\"gaze_unit dot scrnz_unit={torch.dot(gaze_unit, scrnz_unit)}\")\n",
    "    print(f\"gaze_unit dot up={torch.dot(gaze_unit, up)}\")\n",
    "\n",
    "    print(f\"gaze dot up={torch.dot(gaze, up)}\")\n",
    "\n",
    "    #print(f\" dot ={torch.dot(torch.tensor([1.0, -1.0, -1.0], dtype=float, requires_grad=False), torch.tensor([1.0, 1.0, -1.0], dtype=float, requires_grad=False))}\")\n",
    "    #print(f\" dot ={torch.dot(torch.tensor([1.0, -1.0, 1.0], dtype=float, requires_grad=False), torch.tensor([1.0, 1.0, 1.0], dtype=float, requires_grad=False))}\")\n",
    "    #print(f\" dot ={torch.dot(torch.tensor([1.0, -1.0, 0.0], dtype=float, requires_grad=False), torch.tensor([1.0, 1.0, 0.0], dtype=float, requires_grad=False))}\")\n",
    "    #print(f\" dot ={torch.dot(torch.tensor([1.0, -1.0, -1.0], dtype=float, requires_grad=False), torch.tensor([1.0, 1.0, 0.0], dtype=float, requires_grad=False))}\")\n",
    "\n",
    "    print(f\"img_grid=\\n{img_grid}\")\n",
    "    print(f\"eye={eye}\")\n",
    "\n",
    "primary_ray_vectors = img_grid - eye\n",
    "see(\"primary_ray_vectors\", primary_ray_vectors)\n",
    "assert is_float_tensor_on_device(primary_ray_vectors)\n",
    "\n",
    "# sanity check on the edges of the image grid\n",
    "\n",
    "primary_ray_vector_px_ul = primary_ray_vectors[0]\n",
    "primary_ray_vector_px_ll = primary_ray_vectors[int(resy.item()) - 1]\n",
    "primary_ray_vector_px_ur = primary_ray_vectors[primary_ray_vectors.shape[0] - int(resy.item())]\n",
    "primary_ray_vector_px_lr = primary_ray_vectors[primary_ray_vectors.shape[0] - 1]\n",
    "\n",
    "# compare vectors calculated the old and the modern way\n",
    "\n",
    "assert torch.allclose(primary_ray_vector_px_ul, px_ul)\n",
    "assert torch.allclose(primary_ray_vector_px_ul, px_ul)\n",
    "assert torch.allclose(primary_ray_vector_px_ul, px_ul)\n",
    "assert torch.allclose(primary_ray_vector_px_ul, px_ul)\n",
    "\n",
    "print(f\"primary_ray_vectors[middle_pixel_index]={primary_ray_vectors[middle_pixel_index]}\")\n"
   ],
   "metadata": {
    "id": "JjwG9l5h4OId"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# normalize the primary ray vectors so that they become unit vectors\n",
    "\n",
    "primary_ray_vectors_unit = tf.normalize(primary_ray_vectors)\n",
    "see(\"primary_ray_vectors_unit\", primary_ray_vectors_unit)\n",
    "assert is_float_tensor_on_device(primary_ray_vectors_unit)\n",
    "\n",
    "# check that for each primary ray vector the Euclidean norm sqrt(x^2 + y^2 + z^2) is 1.0\n",
    "assert torch.allclose(torch.norm(primary_ray_vectors_unit, dim=1), one_dot_zero)\n",
    "\n",
    "# it follows that for each primary ray vector the squared norm x^2 + y^2 + z^2 is also 1.0\n",
    "assert torch.allclose(torch.mul(primary_ray_vectors_unit, primary_ray_vectors_unit).sum(dim=1), one_dot_zero)\n",
    "\n",
    "# perform sanity checks just to be sure\n",
    "\n",
    "primary_ray_vector_px_ul_unit = primary_ray_vectors_unit[0]\n",
    "primary_ray_vector_px_ll_unit = primary_ray_vectors_unit[int(resy.item()) - 1]\n",
    "primary_ray_vector_px_ur_unit = primary_ray_vectors_unit[primary_ray_vectors.shape[0] - int(resy.item())]\n",
    "primary_ray_vector_px_lr_unit = primary_ray_vectors_unit[primary_ray_vectors.shape[0] - 1]\n",
    "\n",
    "# compare to vectors normalized individually\n",
    "\n",
    "primary_ray_vector_px_ul_unit_alt = tf.normalize(primary_ray_vector_px_ul, dim=0)\n",
    "primary_ray_vector_px_ll_unit_alt = tf.normalize(primary_ray_vector_px_ll, dim=0)\n",
    "primary_ray_vector_px_ur_unit_alt = tf.normalize(primary_ray_vector_px_ur, dim=0)\n",
    "primary_ray_vector_px_lr_unit_alt = tf.normalize(primary_ray_vector_px_lr, dim=0)\n",
    "\n",
    "assert torch.allclose(primary_ray_vector_px_ul_unit, primary_ray_vector_px_ul_unit_alt)\n",
    "assert torch.allclose(primary_ray_vector_px_ll_unit, primary_ray_vector_px_ll_unit_alt)\n",
    "assert torch.allclose(primary_ray_vector_px_ur_unit, primary_ray_vector_px_ur_unit_alt)\n",
    "assert torch.allclose(primary_ray_vector_px_lr_unit, primary_ray_vector_px_lr_unit_alt)\n",
    "\n",
    "# compare to vectors calculated the old way\n",
    "\n",
    "px_ul_unit = tf.normalize(px_ul, dim=0)\n",
    "px_ll_unit = tf.normalize(px_ll, dim=0)\n",
    "px_ur_unit = tf.normalize(px_ur, dim=0)\n",
    "px_lr_unit = tf.normalize(px_lr, dim=0)\n",
    "\n",
    "assert torch.allclose(primary_ray_vector_px_ul_unit, px_ul_unit)\n",
    "assert torch.allclose(primary_ray_vector_px_ll_unit, px_ll_unit)\n",
    "assert torch.allclose(primary_ray_vector_px_ur_unit, px_ur_unit)\n",
    "assert torch.allclose(primary_ray_vector_px_lr_unit, px_lr_unit)\n",
    "\n",
    "print(f\"primary_ray_vectors_unit[middle_pixel_index]={primary_ray_vectors_unit[middle_pixel_index]}\")\n"
   ],
   "metadata": {
    "id": "3i4Vrikxw_OT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define function to compute intersections of rays with spheres\n",
    "\n",
    "def intersect_rays_with_spheres(n_rays, n_spheres, ray_origin_per_sphere, spheres_center, spheres_radius):\n",
    "    # n_rays is the number of rays\n",
    "    \n",
    "    # n_spheres is the number of spheres\n",
    "\n",
    "    # ray_origin_per_sphere contains one row per sphere where each row is the 3D vector of the origin of the ray\n",
    "    # when shooting rays from the camera this is an n by 3 tensor where each row is the eye vector\n",
    "    assert ray_origin_per_sphere.shape == (n_spheres, 3)\n",
    "        \n",
    "    # spheres_center contains one row per sphere where each row is the 3D vector if the center of the sphere\n",
    "    assert spheres_center.shape == (n_spheres, 3)\n",
    "    \n",
    "    # spheres_radius contains one scalar per sphere where each scalar is the radius of the sphere in radians\n",
    "    assert spheres_radius.shape == (n_spheres, )\n",
    "\n",
    "    # notation somewhat aligned with the lecture script\n",
    "    # E = P = eye = where all primary rays start\n",
    "    # D = primary ray = direction from eye to pixel represented as unit vector\n",
    "    # S = center of a sphere\n",
    "    # r = radius of a sphere\n",
    "    # t = distance from eye to intersection point\n",
    "    # R = E + t * D = vector of intersection point\n",
    "    \n",
    "    # compute the coefficient A of the quadratic equation\n",
    "    # A = x_D^2 + y_D^2 + z_D^2 = dot(D, D)\n",
    "    # which is just the dot product of D with itself\n",
    "    # which is 1.0 since the ray direction vectors are unit vectors\n",
    "    a = one_dot_zero    \n",
    "    \n",
    "    # compute the coefficient b of the quadratic equation\n",
    "    # B = 2 * (x_D(x_E - x_S) + y_D(y_E - y_S) + z_D(z_E - z_S)) = 2 * dot(D, E - S)\n",
    "    # compute E - C for all rays with one element-wise matrix subtraction\n",
    "    ray_origin_minus_spheres_center = ray_origin_per_sphere - spheres_center\n",
    "    see(\"ray_origin_minus_spheres_center\", ray_origin_minus_spheres_center, False)\n",
    "    assert is_float_tensor_on_device(ray_origin_minus_spheres_center)\n",
    "    assert ray_origin_minus_spheres_center.shape == (n_spheres, 3)\n",
    "    # we actually compute all dot products with just one matrix multiplication\n",
    "    b = two_dot_zero * torch.matmul(primary_ray_vectors_unit, ray_origin_minus_spheres_center.T)\n",
    "    see(\"b\", b)\n",
    "    assert is_float_tensor_on_device(b)\n",
    "    assert b.shape == (n_rays, n_spheres)\n",
    "    \n",
    "    # compute the coefficient c of the quadratic equation\n",
    "    # C = (x_E - x_S)^2 + (y_E - y_S)^2 + (z_E - z_S)^2 = dot(E - S, E - S)\n",
    "\n",
    "    # compute the square of each radius\n",
    "    spheres_radius_sqaured = torch.square(spheres_radius)\n",
    "    see(\"spheres_radius_sqaured\", spheres_radius_sqaured, False)\n",
    "    assert is_float_tensor_on_device(spheres_radius_sqaured)\n",
    "    assert spheres_radius_sqaured.shape == (n_spheres,)\n",
    "    # we compute all the dot products and all the scalar subtractions in one go\n",
    "    c = torch.sum(torch.mul(ray_origin_minus_spheres_center, ray_origin_minus_spheres_center), dim=1) - spheres_radius_sqaured\n",
    "    see(\"c\", c)\n",
    "    assert is_float_tensor_on_device(c)\n",
    "    assert c.shape == (n_spheres,)  \n",
    "    \n",
    "    # compute the discriminant of the quadratic equation\n",
    "    # discriminant = B^2 - 4 * C\n",
    "    four_dot_zero_times_c_stacked = (four_dot_zero * c).unsqueeze(0).repeat(n_rays, 1)\n",
    "    see(\"four_dot_zero_times_c_stacked\", four_dot_zero_times_c_stacked, False)\n",
    "    assert is_float_tensor_on_device(four_dot_zero_times_c_stacked)\n",
    "    assert four_dot_zero_times_c_stacked.shape == (n_rays, n_spheres)\n",
    "    discriminants = torch.square(b) - four_dot_zero_times_c_stacked\n",
    "    see(\"discriminants\", discriminants, False)\n",
    "    assert is_float_tensor_on_device(discriminants)\n",
    "    assert discriminants.shape == (n_rays, n_spheres)    \n",
    "\n",
    "    # mask discriminants regarding number of intersections between any ray and sphere\n",
    "    spheres_2_solution_indices = discriminants > 1e-8\n",
    "    see(\"spheres_2_solution_indices\", spheres_2_solution_indices, False)\n",
    "    assert spheres_2_solution_indices.shape == (n_rays, n_spheres)\n",
    "    spheres_1_solution_indices = (discriminants > -1e-8) & (discriminants < 1e-8)\n",
    "    see(\"spheres_1_solution_indices\", spheres_1_solution_indices, False)\n",
    "    assert spheres_1_solution_indices.shape == (n_rays, n_spheres)\n",
    "    spheres_0_solution_indices = (discriminants < 1e-8)\n",
    "    see(\"spheres_0_solution_indices\", spheres_0_solution_indices, False)\n",
    "    assert spheres_0_solution_indices.shape == (n_rays, n_spheres)\n",
    "    \n",
    "    # count for how many pairs of rays spheres there are 2, 1, 0 solutions\n",
    "    n_2_solutions = torch.count_nonzero(spheres_2_solution_indices)\n",
    "    see(\"n_2_solutions\", n_2_solutions)\n",
    "    n_1_solutions = torch.count_nonzero(spheres_1_solution_indices)\n",
    "    see(\"n_1_solutions\", n_1_solutions)\n",
    "    n_0_solutions = torch.count_nonzero(spheres_0_solution_indices)\n",
    "    see(\"n_0_solutions\", n_0_solutions)\n",
    "    \n",
    "    # compute the square root of the discriminant of the quadratic equation\n",
    "    # sqrt(discriminant) = sqrt(B^2 - 4 * C)\n",
    "    # note that there are two solutions to the square root if discriminant is > 0\n",
    "    # we accomodate for that by using + and - sign in subsequent formula\n",
    "    discriminants_sqrt = discriminants.clone()\n",
    "    discriminants_sqrt[spheres_2_solution_indices] = torch.sqrt(discriminants[spheres_2_solution_indices])\n",
    "    discriminants_sqrt[spheres_1_solution_indices] = 0.0\n",
    "    discriminants_sqrt[spheres_0_solution_indices] = -1.0\n",
    "    see(\"discriminants_sqrt\", discriminants_sqrt, False)\n",
    "    assert is_float_tensor_on_device(discriminants_sqrt)\n",
    "    assert discriminants_sqrt.shape == (n_rays, n_spheres)\n",
    "    \n",
    "    # compute the distances from the eye to the intersections\n",
    "    # t_0 = (- B - sqrt(B^2 - 4 * C)) / 2 = -0.5 * (B + sqrt(B^2 - 4 * C))\n",
    "    # t_1 = (- B + sqrt(B^2 - 4 * C)) / 2 = -0.5 * (B - sqrt(B^2 - 4 * C))\n",
    "    t_0s = minus_zero_dot_five * (b + discriminants_sqrt)\n",
    "    t_0s[spheres_0_solution_indices] = 0.0\n",
    "    see_more(\"t_0s\", t_0s, False)\n",
    "    assert is_float_tensor_on_device(t_0s)\n",
    "    assert t_0s.shape == (n_rays, n_spheres)\n",
    "    t_1s = minus_zero_dot_five * (b - discriminants_sqrt)\n",
    "    t_1s[spheres_0_solution_indices] = 0.0\n",
    "    see_more(\"t_0s\", t_0s, False)\n",
    "    see_more(\"t_1s\", t_1s, False)\n",
    "    assert is_float_tensor_on_device(t_1s)\n",
    "    assert t_1s.shape == (n_rays, n_spheres)\n",
    "    \n",
    "    # note that in case a sphere would be completely or partially behind the camera\n",
    "    # we would need to cull away all intersections behind the camera\n",
    "    # by setting them to far or infinity before taking the minimum\n",
    "    \n",
    "    # note that the 1 solution case is rare\n",
    "    # and corresponding values in t_0s and t_1s equal\n",
    "    # in that case the minimum function will simply use that value\n",
    "    \n",
    "    ts = torch.minimum(t_0s, t_1s)\n",
    "    ts[spheres_0_solution_indices] = 0.0\n",
    "    see_more(\"ts\", ts, False)\n",
    "    assert is_float_tensor_on_device(ts)\n",
    "    assert ts.shape == (n_rays, n_spheres)\n",
    "    \n",
    "    # determine the minimum t for each ray\n",
    "    #ts[spheres_0_solution_indices] = far + 10.0\n",
    "    ts[spheres_0_solution_indices] = far + 10.0\n",
    "    ts_minimum = torch.min(ts, dim=1)\n",
    "    ts_min = ts_minimum.values\n",
    "    ts_background_mask = ts_min > far\n",
    "    assert ts_background_mask.shape == (n_rays,)\n",
    "    ts_foreground_mask = ts_min <= far\n",
    "    assert ts_foreground_mask.shape == (n_rays,)\n",
    "    ts_foreground_mask_with_0 = ts_foreground_mask.clone()\n",
    "    ts_foreground_mask_with_0[0] = True\n",
    "    ts_min[ts_background_mask] = 0.0\n",
    "    see_more(\"ts_min\", ts_min)\n",
    "    assert is_float_tensor_on_device(ts_min)\n",
    "    assert ts_min.shape == (n_rays,)\n",
    "    \n",
    "    # compute intersection points\n",
    "    # by scaling each primary ray unit vector by the corresponding minimum t\n",
    "    points_hit = torch.mul(primary_ray_vectors_unit, torch.unsqueeze(ts_min, dim=1))\n",
    "    points_hit[ts_background_mask] = zero_vector_float\n",
    "    see_more(\"points_hit\", points_hit)\n",
    "    assert points_hit.shape == (n_pixels, 3)    \n",
    "    \n",
    "    # for each ray note the index of the sphere that the ray hit\n",
    "    #ts_min_spheres_index = torch.remainder(ts_minimum.indices, n_spheres)\n",
    "    spheres_index_hit = torch.remainder(ts_minimum.indices, n_spheres)\n",
    "    see_more(\"ts_min_spheres_index\", spheres_index_hit)\n",
    "    assert is_long_tensor(spheres_index_hit)\n",
    "    assert ts_min.shape == (n_rays,)\n",
    "    \n",
    "     # for each ray get the center of the sphere that the ray hit\n",
    "    spheres_center_hit = spheres_center[spheres_index_hit]\n",
    "    see(\"spheres_center_hit\", spheres_center_hit)\n",
    "    assert is_float_tensor_on_device(spheres_center_hit)\n",
    "    assert spheres_center_hit.shape == (n_rays, 3)\n",
    "    \n",
    "    # also compute surface normal at each intersection in terms of a unit vector\n",
    "    surface_normals_hit = points_hit - spheres_center_hit\n",
    "    surface_normals_hit[ts_background_mask] = zero_vector_float\n",
    "    surface_normals_hit_unit = tf.normalize(surface_normals_hit)\n",
    "    see_more(\"surface_normals_hit_unit\", surface_normals_hit_unit)\n",
    "    assert is_float_tensor_on_device(surface_normals_hit_unit)\n",
    "    \n",
    "    # sanity check\n",
    "    surface_normals_hit_unit_norm = torch.norm(surface_normals_hit_unit, p=2, dim=1, keepdim=True)\n",
    "    see_more(\"surface_normals_unit_norm\", surface_normals_hit_unit_norm, False)\n",
    "    assert is_float_tensor_on_device(surface_normals_hit_unit_norm)\n",
    "    assert torch.allclose(surface_normals_hit_unit_norm[ts_foreground_mask], one_dot_zero)\n",
    "    assert torch.allclose(surface_normals_hit_unit_norm[ts_background_mask], zero_vector_float)    \n",
    "    \n",
    "    background_mask = ts_background_mask\n",
    "    foreground_mask = ts_foreground_mask\n",
    "    foreground_mask_with_0 = ts_foreground_mask_with_0\n",
    "    \n",
    "    return points_hit, surface_normals_hit, surface_normals_hit_unit, spheres_index_hit, spheres_center_hit, background_mask, foreground_mask, foreground_mask_with_0\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# compute intersections of primary rays with spheres\n",
    "\n",
    "# make a tensor that contains one copy of eye per sphere\n",
    "eyes_spheres_center = eye.unsqueeze(0).repeat(n_spheres, 1)\n",
    "see(\"eyes_spheres_center\", eyes_spheres_center, False)\n",
    "assert is_float_tensor_on_device(eyes_spheres_center)\n",
    "assert eyes_spheres_center.shape == (n_spheres, 3)\n",
    "\n",
    "# make a tensor that contains one copy of eye per primary ray\n",
    "eyes_pixels = eye.unsqueeze(0).repeat(n_pixels, 1)\n",
    "assert is_float_tensor_on_device(eyes_pixels)\n",
    "assert eyes_pixels.shape == (n_pixels, 3)\n",
    "see(\"eyes_pixels\", eyes_pixels, False)\n",
    "\n",
    "points_hit, surface_normals_hit, surface_normals_hit_unit, spheres_index_hit, spheres_center_hit, background_mask, foreground_mask, foreground_mask_with_0 = intersect_rays_with_spheres(n_pixels, n_spheres, eyes_spheres_center, spheres_center, spheres_radius)\n",
    "\n",
    "print(f\"spheres_index_hit[middle_pixel_index]={spheres_index_hit[middle_pixel_index]}\")\n",
    "\n",
    "print(f\"spheres_center_hit[middle_pixel_index]={spheres_center_hit[middle_pixel_index]}\")\n",
    "\n",
    "print(f\"points_hit[middle_pixel_index]={points_hit[middle_pixel_index]}\")\n",
    "\n",
    "print(f\"surface_normals_hit[middle_pixel_index]={surface_normals_hit[middle_pixel_index]}\")\n",
    "\n",
    "print(f\"surface_normals_hit_unit[middle_pixel_index]={surface_normals_hit_unit[middle_pixel_index]}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "spheres_rgb_hit = spheres_rgb[spheres_index_hit]\n",
    "see(\"spheres_rgb_hit\", spheres_rgb_hit)\n",
    "assert spheres_rgb_hit.shape == (n_pixels, 3)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_rgb = spheres_rgb_hit.clone()\n",
    "img_rgb[background_mask] = zero_vector_int\n",
    "img_rgb_view = img_rgb.view(resx_int_py, resy_int_py, 3)\n",
    "img_rgb_view_permuted = img_rgb_view.permute(1, 0, 2)\n",
    "assert img_rgb_view_permuted.shape == (resy_int_py, resx_int_py, 3)\n",
    "plt.imshow(img_rgb_view_permuted)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def plot_vectors_with_z_value_as_color(vectors, foreground_mask, clim, cmap):\n",
    "    pcd_pv = pv.PolyData(vectors[foreground_mask].numpy())\n",
    "    pcd_pv['point_color'] = pcd_pv.points[:, 2] # use z values as color\n",
    "    plotter = pv.Plotter()\n",
    "    plotter.add_mesh(pcd_pv,\n",
    "            scalars='point_color',\n",
    "            clim=clim,\n",
    "            cmap=cmap)\n",
    "    return plotter\n",
    "\n",
    "plotter = plot_vectors_with_z_value_as_color(points_hit, foreground_mask_with_0, clim=[6,16], cmap='terrain')\n",
    "plotter.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_vectors_with_magnitude_as_color(vectors, foreground_mask, clim, cmap):\n",
    "    pcd_pv = pv.PolyData(vectors[foreground_mask].numpy())\n",
    "    pcd_pv['point_color'] = torch.norm(vectors[foreground_mask], p=2, dim=1, keepdim=True).numpy()\n",
    "    plotter = pv.Plotter()\n",
    "    plotter.add_mesh(pcd_pv,\n",
    "        scalars='point_color',\n",
    "        clim=clim,\n",
    "        cmap=cmap)\n",
    "    return plotter\n",
    "\n",
    "plotter = plot_vectors_with_magnitude_as_color(surface_normals_hit, foreground_mask_with_0, clim=[0,12], cmap='terrain')\n",
    "plotter.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
