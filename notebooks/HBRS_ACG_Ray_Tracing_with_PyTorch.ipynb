{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "AZ0I2Mm5kE5P",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.210670Z",
     "start_time": "2024-06-23T17:59:14.843481Z"
    }
   },
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as tf\n",
    "import torch.linalg as la\n",
    "import numpy as np\n",
    "#import plotly.graph_objects as go\n",
    "import pyvista as pv\n",
    "\n",
    "#%pip list -v\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "log_level_debug = False\n",
    "log_level_info = True"
   ],
   "metadata": {
    "id": "bzowKooAnZuF",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.215114Z",
     "start_time": "2024-06-23T17:59:17.212382Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# global PyTorch settings\n",
    "\n",
    "# disable gradient tracking not needed in this ray tracer to save compute\n",
    "torch.set_grad_enabled(False)\n"
   ],
   "metadata": {
    "id": "ia7TnKFzgALi",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.222592Z",
     "start_time": "2024-06-23T17:59:17.216414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x121ae87a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.520624Z",
     "start_time": "2024-06-23T17:59:17.225081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# global PyVista settings\n",
    "\n",
    "# render on client-side instead of Jupyter server\n",
    "pv.set_jupyter_backend('client')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# check for Metal Performance Shaders in case of macOS just out of curiosity\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n"
   ],
   "metadata": {
    "id": "KD1vIlngcJ2c",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.541975Z",
     "start_time": "2024-06-23T17:59:17.522073Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device_str = \"cuda\"\n",
    "    device = torch.device(device_str)\n",
    "    print(f\"CUDA is available. Using first GPU.\")\n",
    "else:\n",
    "    device_str = \"cpu\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "print(f\"device={device}\")\n"
   ],
   "metadata": {
    "id": "PoesBXcpFc6x",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.549709Z",
     "start_time": "2024-06-23T17:59:17.543268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Using CPU.\n",
      "device=cpu\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# offer custom utility functions\n",
    "\n",
    "def create_tensor(v):\n",
    "      return torch.tensor(v, dtype=torch.float, requires_grad=False)\n",
    "\n",
    "def create_tensor_on_device(v):\n",
    "      return torch.tensor(v, dtype=torch.float, requires_grad=False).to(device)\n",
    "\n",
    "def is_float_tensor(obj):\n",
    "    return isinstance(obj, torch.FloatTensor) or isinstance(obj, torch.cuda.FloatTensor)\n",
    "\n",
    "def is_float_tensor_on_device(obj):\n",
    "    # obj.device.type is a str\n",
    "    return is_float_tensor(obj) and (device_str == obj.device.type)\n",
    "\n",
    "def is_long_tensor(obj):\n",
    "    return isinstance(obj, torch.LongTensor) or isinstance(obj, torch.cuda.LongTensor)\n",
    "\n",
    "def normalize_vector_custom(v):\n",
    "    return v / torch.max(torch.norm(v), torch.tensor(1e-12, dtype=torch.float))\n",
    "\n",
    "def normalize_vector(v):\n",
    "    return tf.normalize(v, dim=0)\n",
    "\n",
    "def mean_ignoring_zero(t):\n",
    "    mask = t != 0.0\n",
    "    t_mean = (t * mask).sum(dim=0) / mask.sum(dim=0)\n",
    "    return t_mean\n",
    "\n",
    "def see(name, value, critical=True):\n",
    "    if log_level_debug or (critical and log_level_info):\n",
    "        if is_float_tensor(value):\n",
    "            if len(value.shape) == 0:\n",
    "                # scalar\n",
    "                print(f\"{name}={value}\")\n",
    "            elif len(value.shape) == 1:\n",
    "                if value.shape[0] >= 2:\n",
    "                    # vector\n",
    "                    print(f\"torch.norm({name})={torch.norm(value)}\")\n",
    "                print(f\"{name}.shape={value.shape}\")\n",
    "                print(f\"{name}={value}\")\n",
    "            else:\n",
    "               # matrix or higher-dimensional tensor\n",
    "               print(f\"{name}.shape={value.shape}\")\n",
    "               print(f\"{name}=\\n{value}\")\n",
    "        else:\n",
    "            print(f\"{name}={value}\")\n",
    "\n",
    "def see_more(name, value, critical=True):\n",
    "    if log_level_debug or (critical and log_level_info):\n",
    "        see(name, value, critical)\n",
    "        if len(value.shape) > 0:\n",
    "            print(f\"{name}.min()={value.min()}\")\n",
    "            print(f\"{name}.mean()={value.mean(dtype=torch.float)}\")\n",
    "            print(f\"mean_ignoring_zero({name})={mean_ignoring_zero(value)}\")\n",
    "            #print(f\"{name}.mode()={value.mode()}\")\n",
    "            print(f\"{name}.median()={value.median()}\")\n",
    "            print(f\"{name}.max()={value.max()}\")\n"
   ],
   "metadata": {
    "id": "eB0D8O9wxbsA",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.634410Z",
     "start_time": "2024-06-23T17:59:17.551240Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# define constants\n",
    "\n",
    "minus_one_dot_zero = create_tensor_on_device(-1.0)\n",
    "minus_zero_dot_five = create_tensor_on_device(-0.5)\n",
    "zero_dot_zero = create_tensor_on_device(0.0)\n",
    "one_dot_zero = create_tensor_on_device(1.0)\n",
    "two_dot_zero = create_tensor_on_device(2.0)\n",
    "four_dot_zero = create_tensor_on_device(4.0)\n",
    "\n",
    "zero_vector_float = create_tensor_on_device([0.0, 0.0, 0.0])\n",
    "zero_vector_int = torch.tensor([0.0, 0.0, 0.0], dtype=torch.int, requires_grad=False)\n"
   ],
   "metadata": {
    "id": "4D2J_iTflS6X",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.641167Z",
     "start_time": "2024-06-23T17:59:17.636416Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# define spheres\n",
    "\n",
    "# each sphere is defined by its center in camera system coordinates and its radius\n",
    "\n",
    "def create_spheres_1():\n",
    "    spheres_center_py = [[-1.0, 0.0, 8.0], [2.0, -2.0, 12.0], [0.0, 0.0, 20.0], [-8.0, 0.0, 10.0]]\n",
    "    spheres_center_pt = torch.tensor(spheres_center_py, dtype=torch.float, requires_grad=False)\n",
    "    n_spheres = spheres_center_pt.shape[0]\n",
    "    spheres_radius_py = [1.0, 5.0, 10.0, 2.0]\n",
    "    spheres_radius_pt = torch.tensor(spheres_radius_py, dtype=torch.float, requires_grad=False)\n",
    "    spheres_rgb_py = [[150, 90, 200], [255, 144, 0], [255, 255, 255], [255, 0, 0]]\n",
    "    spheres_rgb_pt = torch.tensor(spheres_rgb_py, dtype=torch.int, requires_grad=False)\n",
    "    assert spheres_center_pt.shape == (n_spheres, 3)\n",
    "    assert spheres_radius_pt.shape == (n_spheres,)\n",
    "    assert spheres_rgb_pt.shape == (n_spheres, 3)\n",
    "    return spheres_center_pt, spheres_radius_pt, spheres_rgb_pt\n",
    "\n",
    "spheres_center, spheres_radius, spheres_rgb = create_spheres_1()\n",
    "spheres_center = spheres_center.to(device)\n",
    "spheres_radius = spheres_radius.to(device)\n",
    "spheres_rgb = spheres_rgb.to(device)\n",
    "\n",
    "see(\"spheres_center\", spheres_center)\n",
    "assert is_float_tensor_on_device(spheres_center)\n",
    "\n",
    "see(\"spheres_radius\", spheres_radius)\n",
    "assert is_float_tensor_on_device(spheres_radius)\n",
    "\n",
    "see(\"spheres_rgb\", spheres_rgb)\n",
    "\n",
    "n_spheres = spheres_center.shape[0]\n",
    "assert n_spheres == 4"
   ],
   "metadata": {
    "id": "VkgtmBagh4vm",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.653739Z",
     "start_time": "2024-06-23T17:59:17.642871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spheres_center.shape=torch.Size([4, 3])\n",
      "spheres_center=\n",
      "tensor([[-1.,  0.,  8.],\n",
      "        [ 2., -2., 12.],\n",
      "        [ 0.,  0., 20.],\n",
      "        [-8.,  0., 10.]])\n",
      "torch.norm(spheres_radius)=11.401754379272461\n",
      "spheres_radius.shape=torch.Size([4])\n",
      "spheres_radius=tensor([ 1.,  5., 10.,  2.])\n",
      "spheres_rgb=tensor([[150,  90, 200],\n",
      "        [255, 144,   0],\n",
      "        [255, 255, 255],\n",
      "        [255,   0,   0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.677147Z",
     "start_time": "2024-06-23T17:59:17.657725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the camera\n",
    "\n",
    "near = create_tensor_on_device(0.1)\n",
    "far = create_tensor_on_device(100.0)\n",
    "\n",
    "resx_float_py = 1920.0\n",
    "resy_float_py = 1080.0\n",
    "resx_int_py = int(resx_float_py)\n",
    "resy_int_py = int(resy_float_py)\n",
    "resx = create_tensor_on_device(resx_float_py)\n",
    "resy = create_tensor_on_device(resy_float_py)\n",
    "\n",
    "middle_pixel_index = int((resy_int_py / 2) * resx_int_py + (resy_int_py / 2))\n",
    "\n",
    "n_pixels = int((resx * resy).item())\n",
    "see(\"n_pixels\", n_pixels)\n",
    "assert isinstance(n_pixels, int)\n",
    "\n",
    "resx_half = resx / two_dot_zero\n",
    "resy_half = resy / two_dot_zero\n",
    "\n",
    "see(\"far\", far)\n",
    "see(\"near\", near)\n",
    "see(\"resx\", resx)\n",
    "see(\"resy\", resy)\n",
    "see(\"resx_half\", resx_half)\n",
    "see(\"resy_half\", resy_half)\n",
    "\n",
    "# position of the eye point\n",
    "#eye = create_tensor_on_device([0.22, 0.0, -0.44])\n",
    "eye = create_tensor_on_device([0.0, 0.0, 0.0])\n",
    "see(\"eye\", eye)\n",
    "see(\"eye.type\", eye.type())\n",
    "see(\"eye.device\", eye.device)\n",
    "assert is_float_tensor_on_device(eye)\n",
    "\n",
    "# upright direction of the camera orientation\n",
    "up = create_tensor_on_device([0.0, 1.0, 0.0])\n",
    "up = tf.normalize(up, dim=0)\n",
    "assert torch.allclose(up, normalize_vector_custom(up))\n",
    "assert torch.allclose(up, normalize_vector(up))\n",
    "see(\"up\", up)\n",
    "assert is_float_tensor_on_device(up)\n",
    "\n",
    "# look is center of image plane\n",
    "#look = create_tensor_on_device([1.0, 0.0, 2.0])\n",
    "look = create_tensor_on_device([0.0, 0.0, 1.5])\n",
    "see(\"look\", look)\n",
    "assert is_float_tensor_on_device(look)\n",
    "\n",
    "gaze = look - eye\n",
    "assert is_float_tensor_on_device(gaze)\n",
    "\n",
    "# distance from the eye to center of image plane\n",
    "distance_intrinsic = torch.norm(gaze)\n",
    "see(\"distance_intrinsic\", distance_intrinsic)\n",
    "assert is_float_tensor_on_device(distance_intrinsic)\n",
    "\n",
    "# direction from eye towards center of image plane\n",
    "gaze_unit = tf.normalize(gaze, dim=0)\n",
    "see(\"gaze\", gaze)\n",
    "see(\"gaze_unit\", gaze_unit)\n",
    "assert torch.isclose(torch.norm(gaze_unit), torch.tensor(1., dtype=torch.float, requires_grad=False))\n",
    "assert is_float_tensor_on_device(gaze_unit)\n",
    "\n",
    "scrnx_unit = la.cross(up, gaze_unit, dim=0)\n",
    "scrnx_unit = tf.normalize(scrnx_unit, dim=0)\n",
    "assert torch.isclose(torch.norm(scrnx_unit), torch.tensor(1., dtype=torch.float, requires_grad=False))\n",
    "# !? hack to get numerically perfect scrnx in special case\n",
    "scrnx_unit_perfect = create_tensor_on_device([1.,0.,0.])\n",
    "if torch.allclose(scrnx_unit, scrnx_unit_perfect):\n",
    "    print(\"Using perfect scrnx_unit.\")\n",
    "    scrnx_unit = scrnx_unit_perfect\n",
    "see(\"scrnx_unit\", scrnx_unit)\n",
    "assert is_float_tensor_on_device(scrnx_unit)\n",
    "\n",
    "scrny_unit = la.cross(gaze_unit, scrnx_unit, dim=0)\n",
    "scrny_unit = tf.normalize(scrny_unit, dim=0)\n",
    "assert torch.isclose(torch.norm(scrny_unit), torch.tensor(1., dtype=torch.float, requires_grad=False))\n",
    "# !? hack to get numerically perfect scrny in special case\n",
    "scrny_unit_perfect = create_tensor_on_device([0.,1.,0.])\n",
    "if torch.allclose(scrny_unit, scrny_unit_perfect):\n",
    "    print(\"Using perfect scrny_unit.\")\n",
    "    scrny_unit = scrny_unit_perfect\n",
    "see(\"scrny_unit\", scrny_unit)\n",
    "assert is_float_tensor_on_device(scrny_unit)\n",
    "\n",
    "# !? note that we compute scrnz so it points towards the eye\n",
    "# i.e. it is the most reasonable normal of the image plane\n",
    "scrnz_unit = la.cross(scrnx_unit, scrny_unit, dim=0)\n",
    "scrnz_unit = tf.normalize(scrnz_unit, dim=0)\n",
    "# !? hack to get numerically perfect scrnz in special case\n",
    "scrnz_unit_perfect = create_tensor_on_device([0.,0.,1.])\n",
    "if torch.allclose(scrnz_unit, scrnz_unit_perfect):\n",
    "    print(\"Using perfect scrnz_unit.\")\n",
    "    scrnz_unit = scrnz_unit_perfect\n",
    "see(\"scrnz_unit\", scrnz_unit)\n",
    "assert is_float_tensor_on_device(scrnz_unit)\n",
    "\n",
    "# note that fovx is actually representing half of the horizontal field of view\n",
    "fovx_degrees = create_tensor_on_device(50.0)\n",
    "see(\"fovx_degrees\", fovx_degrees)\n",
    "assert is_float_tensor_on_device(fovx_degrees)\n",
    "\n",
    "fovx_radians = torch.deg2rad(fovx_degrees)\n",
    "see(\"fovx_radians\", fovx_radians)\n",
    "assert is_float_tensor_on_device(fovx_radians)\n",
    "\n",
    "# note that fovy is actually representing half of the vertical field of view\n",
    "fovy_degrees = fovx_degrees / (resx / resy)\n",
    "# resx and resy are already tensors thus no neeed to wrap resx / resy\n",
    "#fovy_degrees = fovx_degrees / torch.tensor(resx / resy, dtype=torch.float)\n",
    "see(\"fovy_degrees\", fovy_degrees)\n",
    "assert is_float_tensor_on_device(fovy_degrees)\n",
    "\n",
    "# override fovy to optimize magnitude of a pixel in y direction\n",
    "fovy_degrees = create_tensor_on_device(33.83)\n",
    "see(\"fovy_degrees\", fovy_degrees)\n",
    "assert is_float_tensor_on_device(fovy_degrees)\n",
    "\n",
    "fovy_radians = torch.deg2rad(fovy_degrees)\n",
    "see(\"fovy_radians\", fovy_radians)\n",
    "assert is_float_tensor_on_device(fovy_radians)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_pixels=2073600\n",
      "far=100.0\n",
      "near=0.10000000149011612\n",
      "resx=1920.0\n",
      "resy=1080.0\n",
      "resx_half=960.0\n",
      "resy_half=540.0\n",
      "torch.norm(eye)=0.0\n",
      "eye.shape=torch.Size([3])\n",
      "eye=tensor([0., 0., 0.])\n",
      "eye.type=torch.FloatTensor\n",
      "eye.device=cpu\n",
      "torch.norm(up)=1.0\n",
      "up.shape=torch.Size([3])\n",
      "up=tensor([0., 1., 0.])\n",
      "torch.norm(look)=1.5\n",
      "look.shape=torch.Size([3])\n",
      "look=tensor([0.0000, 0.0000, 1.5000])\n",
      "distance_intrinsic=1.5\n",
      "torch.norm(gaze)=1.5\n",
      "gaze.shape=torch.Size([3])\n",
      "gaze=tensor([0.0000, 0.0000, 1.5000])\n",
      "torch.norm(gaze_unit)=1.0\n",
      "gaze_unit.shape=torch.Size([3])\n",
      "gaze_unit=tensor([0., 0., 1.])\n",
      "Using perfect scrnx_unit.\n",
      "torch.norm(scrnx_unit)=1.0\n",
      "scrnx_unit.shape=torch.Size([3])\n",
      "scrnx_unit=tensor([1., 0., 0.])\n",
      "Using perfect scrny_unit.\n",
      "torch.norm(scrny_unit)=1.0\n",
      "scrny_unit.shape=torch.Size([3])\n",
      "scrny_unit=tensor([0., 1., 0.])\n",
      "Using perfect scrnz_unit.\n",
      "torch.norm(scrnz_unit)=1.0\n",
      "scrnz_unit.shape=torch.Size([3])\n",
      "scrnz_unit=tensor([0., 0., 1.])\n",
      "fovx_degrees=50.0\n",
      "fovx_radians=0.8726646304130554\n",
      "fovy_degrees=28.125\n",
      "fovy_degrees=33.83000183105469\n",
      "fovy_radians=0.5904449224472046\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.686033Z",
     "start_time": "2024-06-23T17:59:17.678904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute size of a pixel and scale scrnx and scrny accordingly\n",
    "\n",
    "def compute_magnitude_of_a_pixel(distance, fov_radians, res, two_dot_zero):\n",
    "     mag = torch.abs(two_dot_zero * distance * (torch.tan(fov_radians) / res))\n",
    "     assert is_float_tensor_on_device(mag)\n",
    "     return mag\n",
    "\n",
    "# magx is the length aka. magnitude of a pixel in direction scrnx\n",
    "magx = compute_magnitude_of_a_pixel(distance_intrinsic, fovx_radians, resx, two_dot_zero)\n",
    "scrnx_scaled = scrnx_unit * magx\n",
    "# scrnx is now 1 pixel long in horizontal direction of the image plane\n",
    "see(\"scrnx_scaled\", scrnx_scaled)\n",
    "assert torch.isclose(torch.norm(scrnx_scaled), magx)\n",
    "assert is_float_tensor_on_device(magx)\n",
    "assert is_float_tensor_on_device(scrnx_scaled)\n",
    "\n",
    "# magy is the length aka. magnitude of a pixel in direction scrny\n",
    "magy = compute_magnitude_of_a_pixel(distance_intrinsic, fovy_radians, resy, two_dot_zero)\n",
    "scrny_scaled = scrny_unit * magy\n",
    "# scrny is now 1 pixel long in vertical direction of the image plane\n",
    "see(\"scrny_scaled\", scrny_scaled)\n",
    "assert torch.isclose(torch.norm(scrny_scaled), magy)\n",
    "assert is_float_tensor_on_device(magy)\n",
    "assert is_float_tensor_on_device(scrny_scaled)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.norm(scrnx_scaled)=0.0018621149938553572\n",
      "scrnx_scaled.shape=torch.Size([3])\n",
      "scrnx_scaled=tensor([0.0019, 0.0000, 0.0000])\n",
      "torch.norm(scrny_scaled)=0.0018616672605276108\n",
      "scrny_scaled.shape=torch.Size([3])\n",
      "scrny_scaled=tensor([0.0000, 0.0019, 0.0000])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.700893Z",
     "start_time": "2024-06-23T17:59:17.687642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute position of the pixel in the upper left corner of the image plane relative to the eye\n",
    "\n",
    "def scale_scrn_vectors(scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero):\n",
    "    ox = scrnx * ((resx / two_dot_zero) - resx_off)\n",
    "    oy = scrny * ((resy / two_dot_zero) - resy_off)\n",
    "    return ox, oy\n",
    "\n",
    "def compute_relative_position_of_pixel_upper_left(gaze, scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero):\n",
    "     # we assume that gaze is pointing exactly to the middle of the image plane\n",
    "     # i.e. gaze is pointing at the center of the tiny cross\n",
    "     # between the four mid-most pixels\n",
    "     ox, oy = scale_scrn_vectors(scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero)\n",
    "     px_ul_pos = gaze - ox + oy\n",
    "     assert is_float_tensor_on_device(px_ul_pos)\n",
    "     return px_ul_pos\n",
    "\n",
    "# we also compute these relative positions of some other pixels just for sanity checks\n",
    "\n",
    "def compute_relative_position_of_pixel_lower_left(gaze, scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero):\n",
    "     # we assume that gaze is pointing exactly to the middle of the image plane\n",
    "     # i.e. gaze is pointing at the center of the tiny cross\n",
    "     # between the four mid-most pixels\n",
    "     ox, oy = scale_scrn_vectors(scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero)\n",
    "     px_ll_pos = gaze - ox - oy\n",
    "     assert is_float_tensor_on_device(px_ll_pos)\n",
    "     return px_ll_pos\n",
    "\n",
    "def compute_relative_position_of_pixel_upper_right(gaze, scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero):\n",
    "     # we assume that gaze is pointing exactly to the middle of the image plane\n",
    "     # i.e. gaze is pointing at the center of the tiny cross\n",
    "     # between the four mid-most pixels\n",
    "     ox, oy = scale_scrn_vectors(scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero)\n",
    "     px_ur_pos = gaze + ox + oy\n",
    "     assert is_float_tensor_on_device(px_ur_pos)\n",
    "     return px_ur_pos\n",
    "\n",
    "def compute_relative_position_of_pixel_lower_right(gaze, scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero):\n",
    "     # we assume that gaze is pointing exactly to the middle of the image plane\n",
    "     # i.e. gaze is pointing at the center of the tiny cross\n",
    "     # between the four mid-most pixels\n",
    "     ox, oy = scale_scrn_vectors(scrnx, resx, resx_off, scrny, resy, resy_off, two_dot_zero)\n",
    "     px_lr_pos = gaze + ox - oy\n",
    "     assert is_float_tensor_on_device(px_lr_pos)\n",
    "     return px_lr_pos\n",
    "\n",
    "# factors to ensure computed positions are the middle of pixels\n",
    "resx_off = create_tensor_on_device(0.5)\n",
    "resy_off = create_tensor_on_device(0.5)\n",
    "assert is_float_tensor_on_device(resx_off)\n",
    "assert is_float_tensor_on_device(resy_off)\n",
    "\n",
    "px_ul = compute_relative_position_of_pixel_upper_left(gaze, scrnx_scaled, resx, resx_off, scrny_scaled, resy, resy_off, two_dot_zero)\n",
    "see(\"px_ul\", px_ul)\n",
    "\n",
    "px_ll = compute_relative_position_of_pixel_lower_left(gaze, scrnx_scaled, resx, resx_off, scrny_scaled, resy, resy_off, two_dot_zero)\n",
    "see(\"px_ll\", px_ll)\n",
    "\n",
    "px_ur = compute_relative_position_of_pixel_upper_right(gaze, scrnx_scaled, resx, resx_off, scrny_scaled, resy, resy_off, two_dot_zero)\n",
    "see(\"px_ur\", px_ur)\n",
    "\n",
    "px_lr = compute_relative_position_of_pixel_lower_right(gaze, scrnx_scaled, resx, resx_off, scrny_scaled, resy, resy_off, two_dot_zero)\n",
    "see(\"px_lr\", px_lr)\n",
    "\n",
    "distance_px_ul_px_ur = torch.norm(px_ul - px_ur)\n",
    "see(\"distance_px_ul_px_ur\", distance_px_ul_px_ur)\n",
    "\n",
    "# note that a pixel position vector points to the middle of a pixel\n",
    "# therefore when calculating a width of the image plane\n",
    "# we count two times half a pixel less\n",
    "# which is represented here by subtracting resx_off twice before scaling\n",
    "distance_px_ul_px_ur_anticipated = (resx - resx_off - resx_off) * magx\n",
    "see(\"distance_px_ul_px_ur_anticipated\", distance_px_ul_px_ur_anticipated, False)\n",
    "\n",
    "assert torch.isclose(distance_px_ul_px_ur, distance_px_ul_px_ur_anticipated)\n",
    "\n",
    "distance_px_ul_px_ll = torch.norm(px_ul - px_ll)\n",
    "see(\"distance_px_ul_px_ll\", distance_px_ul_px_ll, False)\n",
    "\n",
    "# note that a pixel position vector points to the middle of a pixel\n",
    "# therefore when calculating a height of the image plane\n",
    "# we count two times half a pixel less\n",
    "# which is represented here by subtracting resy_off twice before scaling\n",
    "distance_px_ul_px_ll_anticipated = (resy - resy_off - resy_off) * magy\n",
    "see(\"distance_px_ul_px_ll_anticipated\", distance_px_ul_px_ll_anticipated, False)\n",
    "\n",
    "assert torch.isclose(distance_px_ul_px_ll, distance_px_ul_px_ll_anticipated)\n",
    "\n",
    "distance_aspect_ratio = distance_px_ul_px_ur / distance_px_ul_px_ll\n",
    "see(\"distance_aspect_ratio\", distance_aspect_ratio, False)\n",
    "\n",
    "distance_aspect_ratio_anticipated = distance_px_ul_px_ur / distance_px_ul_px_ll\n",
    "see(\"distance_aspect_ratio_anticipated\", distance_aspect_ratio_anticipated, False)\n",
    "\n",
    "if fovy_degrees.item() == 33.83:\n",
    "    distance_aspect_ratio_anticipated_also = resx / resy\n",
    "    see(\"distance_aspect_ratio_anticipated_also\", distance_aspect_ratio_anticipated_also, False)\n",
    "\n",
    "    assert torch.isclose(distance_aspect_ratio, distance_aspect_ratio_anticipated_also, rtol=1e-03)\n",
    "\n",
    "    distance_aspect_ratio_anticipated_moreover = create_tensor_on_device(16.0 / 9.0)\n",
    "    see(\"distance_aspect_ratio_anticipated_moreover\", distance_aspect_ratio_anticipated_moreover, False)\n",
    "\n",
    "    assert torch.isclose(distance_aspect_ratio, distance_aspect_ratio_anticipated_moreover, rtol=1e-03)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.norm(px_ul)=2.5398921966552734\n",
      "px_ul.shape=torch.Size([3])\n",
      "px_ul=tensor([-1.7867,  1.0044,  1.5000])\n",
      "torch.norm(px_ll)=2.5398921966552734\n",
      "px_ll.shape=torch.Size([3])\n",
      "px_ll=tensor([-1.7867, -1.0044,  1.5000])\n",
      "torch.norm(px_ur)=2.5398921966552734\n",
      "px_ur.shape=torch.Size([3])\n",
      "px_ur=tensor([1.7867, 1.0044, 1.5000])\n",
      "torch.norm(px_lr)=2.5398921966552734\n",
      "px_lr.shape=torch.Size([3])\n",
      "px_lr=tensor([ 1.7867, -1.0044,  1.5000])\n",
      "distance_px_ul_px_ur=3.5733985900878906\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# compute the grid of vectors that form the image plane\n",
    "\n",
    "# each pixel will be represented by a vector pointing to its middle\n",
    "\n",
    "# create a vector per pixel on the image plane\n",
    "# with each pixel 1.0 wide and 1.0 high\n",
    "# and with the center of the image plane is the origin\n",
    "\n",
    "img_grid_original_firstx = minus_one_dot_zero * ((resx / two_dot_zero) - resx_off)\n",
    "img_grid_original_lastx = ((resx / two_dot_zero) - resx_off + one_dot_zero)\n",
    "img_grid_original_firsty =((resy / two_dot_zero) - resy_off)\n",
    "img_grid_original_lasty = minus_one_dot_zero * ((resy / two_dot_zero) - resy_off + one_dot_zero)\n",
    "\n",
    "img_grid_original = torch.cartesian_prod(torch.arange(start=img_grid_original_firstx, end=img_grid_original_lastx, step=1.0, dtype=torch.float, requires_grad=False),\n",
    "                                         torch.arange(start=img_grid_original_firsty, end=img_grid_original_lasty, step=-1.0, dtype=torch.float, requires_grad=False),\n",
    "                                         torch.tensor([0.0], dtype=torch.float, requires_grad=False))\n",
    "see(\"img_grid_original\", img_grid_original)\n",
    "img_grid_original = img_grid_original.to(device)\n",
    "assert is_float_tensor_on_device(img_grid_original)\n",
    "\n",
    "n_pixels_anticipated = img_grid_original.shape[0]\n",
    "assert isinstance(n_pixels_anticipated, int)\n",
    "assert n_pixels == n_pixels_anticipated\n",
    "\n",
    "# scale the image plane using the width of a pixel and the height of a pixel\n",
    "\n",
    "identity_matrix_3_by_3 = torch.eye(3, dtype=torch.float, requires_grad=False).to(device)\n",
    "img_grid_scaling_matrix = identity_matrix_3_by_3 * create_tensor_on_device([magx, magy, 0.0])\n",
    "see(\"img_grid_scaling_matrix\", img_grid_scaling_matrix, False)\n",
    "assert is_float_tensor_on_device(img_grid_scaling_matrix)\n",
    "\n",
    "img_grid_scaled = torch.matmul(img_grid_original, img_grid_scaling_matrix)\n",
    "see(\"img_grid_scaled\", img_grid_scaled, False)\n",
    "assert is_float_tensor_on_device(img_grid_scaled)\n",
    "\n",
    "distance_px_ul_px_lr = torch.norm(px_ul - px_lr)\n",
    "see(\"distance_px_ul_px_lr\", distance_px_ul_px_lr, False)\n",
    "\n",
    "distance_px_ul_px_lr_after_scaling = torch.norm(img_grid_scaled[n_pixels - 1] - img_grid_scaled[0])\n",
    "see(\"distance_px_ul_px_lr_after_scaling\", distance_px_ul_px_lr_after_scaling, False)\n",
    "\n",
    "assert is_float_tensor_on_device(distance_px_ul_px_lr_after_scaling)\n",
    "assert torch.isclose(distance_px_ul_px_lr, distance_px_ul_px_lr_after_scaling)\n",
    "\n",
    "# rotate the image plane around the origin\n",
    "\n",
    "scrnz_unit_neg = normalize_vector(minus_one_dot_zero * scrnz_unit)\n",
    "assert is_float_tensor_on_device(scrnz_unit_neg)\n",
    "\n",
    "img_grid_rotation_matrix = torch.stack([scrnx_unit, scrny_unit, scrnz_unit_neg], dim=1)\n",
    "#img_grid_rotation_matrix = torch.stack([scrnx_unit, scrny_unit, scrnz_unit], dim=1)\n",
    "assert is_float_tensor_on_device(img_grid_rotation_matrix)\n",
    "see(\"img_grid_rotation_matrix\", img_grid_rotation_matrix, False)\n",
    "\n",
    "img_grid_rotated_px_ul = img_grid_rotation_matrix @ img_grid_scaled[0]\n",
    "see(\"img_grid_rotated_px_ul\", img_grid_rotated_px_ul, False)\n",
    "\n",
    "img_grid_rotated_px_lr = img_grid_rotation_matrix @ img_grid_scaled[n_pixels - 1]\n",
    "see(\"img_grid_rotated_px_lr\", img_grid_rotated_px_lr, False)\n",
    "\n",
    "img_grid_rotated = torch.matmul(img_grid_scaled, img_grid_rotation_matrix)\n",
    "see(\"img_grid_rotated\", img_grid_rotated, False)\n",
    "\n",
    "distance_px_ul_px_lr_after_rotation = torch.norm(img_grid_rotated[n_pixels - 1] - img_grid_rotated[0])\n",
    "see(\"distance_px_ul_px_lr_after_rotation\", distance_px_ul_px_lr_after_rotation, False)\n",
    "\n",
    "assert torch.isclose(distance_px_ul_px_lr_after_scaling, distance_px_ul_px_lr_after_rotation)\n",
    "assert torch.isclose(distance_px_ul_px_lr, distance_px_ul_px_lr_after_rotation)\n",
    "\n",
    "# then we translate the image plane into position\n",
    "\n",
    "# translage by look\n",
    "\n",
    "img_grid_translated_by_look = img_grid_rotated + look\n",
    "see(\"img_grid_translated_by_look\", img_grid_translated_by_look, False)\n",
    "\n",
    "distance_px_ul_px_lr_after_translation_by_look = torch.norm(img_grid_translated_by_look[n_pixels - 1] - img_grid_translated_by_look[0])\n",
    "see(\"distance_px_ul_px_lr_after_translation_by_look\", distance_px_ul_px_lr_after_translation_by_look, False)\n",
    "\n",
    "assert torch.isclose(distance_px_ul_px_lr_after_scaling, distance_px_ul_px_lr_after_translation_by_look)\n",
    "assert torch.isclose(distance_px_ul_px_lr_after_scaling, distance_px_ul_px_lr_after_translation_by_look)\n",
    "assert torch.isclose(distance_px_ul_px_lr, distance_px_ul_px_lr_after_translation_by_look)\n",
    "\n",
    "# translate by eye and gaze\n",
    "\n",
    "img_grid_translated_by_eye_and_gaze = img_grid_rotated + eye + gaze\n",
    "see(\"img_grid_translated_by_eye_and_gaze\", img_grid_translated_by_eye_and_gaze, False)\n",
    "\n",
    "distance_px_ul_px_lr_after_translation_by_eye_and_gaze = torch.norm(img_grid_translated_by_eye_and_gaze[n_pixels - 1] - img_grid_translated_by_eye_and_gaze[0])\n",
    "see(\"distance_px_ul_px_lr_after_translation_by_eye_and_gaze\", distance_px_ul_px_lr_after_translation_by_eye_and_gaze, False)\n",
    "\n",
    "assert torch.isclose(distance_px_ul_px_lr_after_scaling, distance_px_ul_px_lr_after_translation_by_eye_and_gaze)\n",
    "assert torch.isclose(distance_px_ul_px_lr_after_scaling, distance_px_ul_px_lr_after_translation_by_eye_and_gaze)\n",
    "assert torch.isclose(distance_px_ul_px_lr, distance_px_ul_px_lr_after_translation_by_eye_and_gaze)\n",
    "\n",
    "# as expected these translations result in the same grid\n",
    "\n",
    "assert torch.allclose(img_grid_translated_by_look, img_grid_translated_by_eye_and_gaze, rtol=0.1)\n",
    "\n",
    "img_grid = img_grid_translated_by_look\n",
    "assert is_float_tensor_on_device(img_grid)\n",
    "see(\"img_grid\", img_grid)\n"
   ],
   "metadata": {
    "id": "6BI8OtiFfFsZ",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.849231Z",
     "start_time": "2024-06-23T17:59:17.702640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_grid_original.shape=torch.Size([2073600, 3])\n",
      "img_grid_original=\n",
      "tensor([[-959.5000,  539.5000,    0.0000],\n",
      "        [-959.5000,  538.5000,    0.0000],\n",
      "        [-959.5000,  537.5000,    0.0000],\n",
      "        ...,\n",
      "        [ 959.5000, -537.5000,    0.0000],\n",
      "        [ 959.5000, -538.5000,    0.0000],\n",
      "        [ 959.5000, -539.5000,    0.0000]])\n",
      "img_grid.shape=torch.Size([2073600, 3])\n",
      "img_grid=\n",
      "tensor([[-1.7867,  1.0044,  1.5000],\n",
      "        [-1.7867,  1.0025,  1.5000],\n",
      "        [-1.7867,  1.0006,  1.5000],\n",
      "        ...,\n",
      "        [ 1.7867, -1.0006,  1.5000],\n",
      "        [ 1.7867, -1.0025,  1.5000],\n",
      "        [ 1.7867, -1.0044,  1.5000]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# compute a direction vector per primary ray\n",
    "\n",
    "# since we have the image grid\n",
    "# this is now just one parallelized operation\n",
    "\n",
    "if log_level_debug:\n",
    "    print(f\"eye={eye}\")\n",
    "    print(f\"look={look}\")\n",
    "    print(f\"gaze={gaze}\")\n",
    "    print(f\"up={up}\")\n",
    "\n",
    "    print(f\"scrnx_unit={scrnx_unit}\")\n",
    "    print(f\"scrny_unit={scrny_unit}\")\n",
    "    print(f\"scrnz_unit={scrnz_unit}\")\n",
    "\n",
    "    print(f\"scrnx_unit dot scrny_unit={torch.dot(scrnx_unit, scrny_unit)}\")\n",
    "    print(f\"scrnx_unit dot scrnz_unit={torch.dot(scrnx_unit, scrnz_unit)}\")\n",
    "    print(f\"scrny_unit dot scrnz_unit={torch.dot(scrny_unit, scrnz_unit)}\")\n",
    "\n",
    "    print(f\"scrnx_scaled dot scrny_scaled={torch.dot(scrnx_scaled, scrny_scaled)}\")\n",
    "    print(f\"scrnx_scaled dot scrnz_unit={torch.dot(scrnx_scaled, scrnz_unit)}\")\n",
    "    print(f\"scrny_scaled dot scrnz_unit={torch.dot(scrny_scaled, scrnz_unit)}\")\n",
    "\n",
    "    print(f\"scrnx_unit dot gaze={torch.dot(scrnx_unit, gaze)}\")\n",
    "    print(f\"scrny_unit dot gaze={torch.dot(scrny_unit, gaze)}\")\n",
    "\n",
    "    print(f\"gaze_unit dot scrnz_unit={torch.dot(gaze_unit, scrnz_unit)}\")\n",
    "    print(f\"gaze_unit dot up={torch.dot(gaze_unit, up)}\")\n",
    "\n",
    "    print(f\"gaze dot up={torch.dot(gaze, up)}\")\n",
    "\n",
    "    #print(f\" dot ={torch.dot(torch.tensor([1.0, -1.0, -1.0], dtype=float, requires_grad=False), torch.tensor([1.0, 1.0, -1.0], dtype=float, requires_grad=False))}\")\n",
    "    #print(f\" dot ={torch.dot(torch.tensor([1.0, -1.0, 1.0], dtype=float, requires_grad=False), torch.tensor([1.0, 1.0, 1.0], dtype=float, requires_grad=False))}\")\n",
    "    #print(f\" dot ={torch.dot(torch.tensor([1.0, -1.0, 0.0], dtype=float, requires_grad=False), torch.tensor([1.0, 1.0, 0.0], dtype=float, requires_grad=False))}\")\n",
    "    #print(f\" dot ={torch.dot(torch.tensor([1.0, -1.0, -1.0], dtype=float, requires_grad=False), torch.tensor([1.0, 1.0, 0.0], dtype=float, requires_grad=False))}\")\n",
    "\n",
    "    print(f\"img_grid=\\n{img_grid}\")\n",
    "    print(f\"eye={eye}\")\n",
    "\n",
    "primary_ray_vectors = img_grid - eye\n",
    "see(\"primary_ray_vectors\", primary_ray_vectors)\n",
    "assert is_float_tensor_on_device(primary_ray_vectors)\n",
    "\n",
    "# sanity check on the edges of the image grid\n",
    "\n",
    "primary_ray_vector_px_ul = primary_ray_vectors[0]\n",
    "primary_ray_vector_px_ll = primary_ray_vectors[int(resy.item()) - 1]\n",
    "primary_ray_vector_px_ur = primary_ray_vectors[primary_ray_vectors.shape[0] - int(resy.item())]\n",
    "primary_ray_vector_px_lr = primary_ray_vectors[primary_ray_vectors.shape[0] - 1]\n",
    "\n",
    "# compare vectors calculated the old and the modern way\n",
    "\n",
    "assert torch.allclose(primary_ray_vector_px_ul, px_ul)\n",
    "assert torch.allclose(primary_ray_vector_px_ul, px_ul)\n",
    "assert torch.allclose(primary_ray_vector_px_ul, px_ul)\n",
    "assert torch.allclose(primary_ray_vector_px_ul, px_ul)\n",
    "\n",
    "print(f\"primary_ray_vectors[middle_pixel_index]={primary_ray_vectors[middle_pixel_index]}\")\n"
   ],
   "metadata": {
    "id": "JjwG9l5h4OId",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.867335Z",
     "start_time": "2024-06-23T17:59:17.851823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary_ray_vectors.shape=torch.Size([2073600, 3])\n",
      "primary_ray_vectors=\n",
      "tensor([[-1.7867,  1.0044,  1.5000],\n",
      "        [-1.7867,  1.0025,  1.5000],\n",
      "        [-1.7867,  1.0006,  1.5000],\n",
      "        ...,\n",
      "        [ 1.7867, -1.0006,  1.5000],\n",
      "        [ 1.7867, -1.0025,  1.5000],\n",
      "        [ 1.7867, -1.0044,  1.5000]])\n",
      "primary_ray_vectors[middle_pixel_index]=tensor([ 9.3106e-04, -9.3083e-04,  1.5000e+00])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# normalize the primary ray vectors so that they become unit vectors\n",
    "\n",
    "primary_ray_vectors_unit = tf.normalize(primary_ray_vectors)\n",
    "see(\"primary_ray_vectors_unit\", primary_ray_vectors_unit)\n",
    "assert is_float_tensor_on_device(primary_ray_vectors_unit)\n",
    "\n",
    "# check that for each primary ray vector the Euclidean norm sqrt(x^2 + y^2 + z^2) is 1.0\n",
    "assert torch.allclose(torch.norm(primary_ray_vectors_unit, dim=1), one_dot_zero)\n",
    "\n",
    "# it follows that for each primary ray vector the squared norm x^2 + y^2 + z^2 is also 1.0\n",
    "assert torch.allclose(torch.mul(primary_ray_vectors_unit, primary_ray_vectors_unit).sum(dim=1), one_dot_zero)\n",
    "\n",
    "# perform cross checks just to be sure\n",
    "\n",
    "primary_ray_vector_px_ul_unit = primary_ray_vectors_unit[0]\n",
    "primary_ray_vector_px_ll_unit = primary_ray_vectors_unit[int(resy.item()) - 1]\n",
    "primary_ray_vector_px_ur_unit = primary_ray_vectors_unit[primary_ray_vectors.shape[0] - int(resy.item())]\n",
    "primary_ray_vector_px_lr_unit = primary_ray_vectors_unit[primary_ray_vectors.shape[0] - 1]\n",
    "\n",
    "# compare to vectors normalized individually\n",
    "\n",
    "primary_ray_vector_px_ul_unit_alt = tf.normalize(primary_ray_vector_px_ul, dim=0)\n",
    "primary_ray_vector_px_ll_unit_alt = tf.normalize(primary_ray_vector_px_ll, dim=0)\n",
    "primary_ray_vector_px_ur_unit_alt = tf.normalize(primary_ray_vector_px_ur, dim=0)\n",
    "primary_ray_vector_px_lr_unit_alt = tf.normalize(primary_ray_vector_px_lr, dim=0)\n",
    "\n",
    "assert torch.allclose(primary_ray_vector_px_ul_unit, primary_ray_vector_px_ul_unit_alt)\n",
    "assert torch.allclose(primary_ray_vector_px_ll_unit, primary_ray_vector_px_ll_unit_alt)\n",
    "assert torch.allclose(primary_ray_vector_px_ur_unit, primary_ray_vector_px_ur_unit_alt)\n",
    "assert torch.allclose(primary_ray_vector_px_lr_unit, primary_ray_vector_px_lr_unit_alt)\n",
    "\n",
    "# compare to vectors calculated the old way\n",
    "\n",
    "px_ul_unit = tf.normalize(px_ul, dim=0)\n",
    "px_ll_unit = tf.normalize(px_ll, dim=0)\n",
    "px_ur_unit = tf.normalize(px_ur, dim=0)\n",
    "px_lr_unit = tf.normalize(px_lr, dim=0)\n",
    "\n",
    "assert torch.allclose(primary_ray_vector_px_ul_unit, px_ul_unit)\n",
    "assert torch.allclose(primary_ray_vector_px_ll_unit, px_ll_unit)\n",
    "assert torch.allclose(primary_ray_vector_px_ur_unit, px_ur_unit)\n",
    "assert torch.allclose(primary_ray_vector_px_lr_unit, px_lr_unit)\n",
    "\n",
    "print(f\"primary_ray_vectors_unit[middle_pixel_index]={primary_ray_vectors_unit[middle_pixel_index]}\")\n"
   ],
   "metadata": {
    "id": "3i4Vrikxw_OT",
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.935359Z",
     "start_time": "2024-06-23T17:59:17.869710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary_ray_vectors_unit.shape=torch.Size([2073600, 3])\n",
      "primary_ray_vectors_unit=\n",
      "tensor([[-0.7035,  0.3954,  0.5906],\n",
      "        [-0.7037,  0.3948,  0.5907],\n",
      "        [-0.7039,  0.3942,  0.5909],\n",
      "        ...,\n",
      "        [ 0.7039, -0.3942,  0.5909],\n",
      "        [ 0.7037, -0.3948,  0.5907],\n",
      "        [ 0.7035, -0.3954,  0.5906]])\n",
      "primary_ray_vectors_unit[middle_pixel_index]=tensor([ 6.2070e-04, -6.2056e-04,  1.0000e+00])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:17.955512Z",
     "start_time": "2024-06-23T17:59:17.937680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define function to compute intersections of rays with spheres\n",
    "\n",
    "def intersect_rays_with_spheres(n_rays, n_spheres, ray_origin_per_sphere, spheres_center, spheres_radius):\n",
    "    # n_rays is the number of rays\n",
    "    \n",
    "    # n_spheres is the number of spheres\n",
    "\n",
    "    # ray_origin_per_sphere contains one row per sphere where each row is the 3D vector of the origin of the ray\n",
    "    # when shooting rays from the camera this is an n by 3 tensor where each row is the eye vector\n",
    "    assert ray_origin_per_sphere.shape == (n_spheres, 3)\n",
    "        \n",
    "    # spheres_center contains one row per sphere where each row is the 3D vector if the center of the sphere\n",
    "    assert spheres_center.shape == (n_spheres, 3)\n",
    "    \n",
    "    # spheres_radius contains one scalar per sphere where each scalar is the radius of the sphere in radians\n",
    "    assert spheres_radius.shape == (n_spheres, )\n",
    "\n",
    "    # notation somewhat aligned with the lecture script\n",
    "    # E = P = eye = where all primary rays start\n",
    "    # D = primary ray = direction from eye to pixel represented as unit vector\n",
    "    # S = center of a sphere\n",
    "    # r = radius of a sphere\n",
    "    # t = distance from eye to intersection point\n",
    "    # R = E + t * D = vector of intersection point\n",
    "    \n",
    "    # compute the coefficient A of the quadratic equation\n",
    "    # A = x_D^2 + y_D^2 + z_D^2 = dot(D, D)\n",
    "    # which is just the dot product of D with itself\n",
    "    # which is 1.0 since the ray direction vectors are unit vectors\n",
    "    a = one_dot_zero    \n",
    "    \n",
    "    # compute the coefficient b of the quadratic equation\n",
    "    # B = 2 * (x_D(x_E - x_S) + y_D(y_E - y_S) + z_D(z_E - z_S)) = 2 * dot(D, E - S)\n",
    "    # compute E - C for all rays with one element-wise matrix subtraction\n",
    "    ray_origin_minus_spheres_center = ray_origin_per_sphere - spheres_center\n",
    "    see(\"ray_origin_minus_spheres_center\", ray_origin_minus_spheres_center, False)\n",
    "    assert is_float_tensor_on_device(ray_origin_minus_spheres_center)\n",
    "    assert ray_origin_minus_spheres_center.shape == (n_spheres, 3)\n",
    "    # we actually compute all dot products with just one matrix multiplication\n",
    "    b = two_dot_zero * torch.matmul(primary_ray_vectors_unit, ray_origin_minus_spheres_center.T)\n",
    "    see(\"b\", b)\n",
    "    assert is_float_tensor_on_device(b)\n",
    "    assert b.shape == (n_rays, n_spheres)\n",
    "    \n",
    "    # compute the coefficient c of the quadratic equation\n",
    "    # C = (x_E - x_S)^2 + (y_E - y_S)^2 + (z_E - z_S)^2 = dot(E - S, E - S)\n",
    "\n",
    "    # compute the square of each radius\n",
    "    spheres_radius_sqaured = torch.square(spheres_radius)\n",
    "    see(\"spheres_radius_sqaured\", spheres_radius_sqaured, False)\n",
    "    assert is_float_tensor_on_device(spheres_radius_sqaured)\n",
    "    assert spheres_radius_sqaured.shape == (n_spheres,)\n",
    "    # we compute all the dot products and all the scalar subtractions in one go\n",
    "    c = torch.sum(torch.mul(ray_origin_minus_spheres_center, ray_origin_minus_spheres_center), dim=1) - spheres_radius_sqaured\n",
    "    see(\"c\", c)\n",
    "    assert is_float_tensor_on_device(c)\n",
    "    assert c.shape == (n_spheres,)  \n",
    "    \n",
    "    # compute the discriminant of the quadratic equation\n",
    "    # discriminant = B^2 - 4 * C\n",
    "    four_dot_zero_times_c_stacked = (four_dot_zero * c).unsqueeze(0).repeat(n_rays, 1)\n",
    "    see(\"four_dot_zero_times_c_stacked\", four_dot_zero_times_c_stacked, False)\n",
    "    assert is_float_tensor_on_device(four_dot_zero_times_c_stacked)\n",
    "    assert four_dot_zero_times_c_stacked.shape == (n_rays, n_spheres)\n",
    "    discriminants = torch.square(b) - four_dot_zero_times_c_stacked\n",
    "    see(\"discriminants\", discriminants, False)\n",
    "    assert is_float_tensor_on_device(discriminants)\n",
    "    assert discriminants.shape == (n_rays, n_spheres)    \n",
    "\n",
    "    # mask discriminants regarding number of intersections between any ray and sphere\n",
    "    spheres_2_solution_indices = discriminants > 1e-8\n",
    "    see(\"spheres_2_solution_indices\", spheres_2_solution_indices, False)\n",
    "    assert spheres_2_solution_indices.shape == (n_rays, n_spheres)\n",
    "    spheres_1_solution_indices = (discriminants > -1e-8) & (discriminants < 1e-8)\n",
    "    see(\"spheres_1_solution_indices\", spheres_1_solution_indices, False)\n",
    "    assert spheres_1_solution_indices.shape == (n_rays, n_spheres)\n",
    "    spheres_0_solution_indices = (discriminants < 1e-8)\n",
    "    see(\"spheres_0_solution_indices\", spheres_0_solution_indices, False)\n",
    "    assert spheres_0_solution_indices.shape == (n_rays, n_spheres)\n",
    "    \n",
    "    # count for how many pairs of rays spheres there are 2, 1, 0 solutions\n",
    "    n_2_solutions = torch.count_nonzero(spheres_2_solution_indices)\n",
    "    see(\"n_2_solutions\", n_2_solutions)\n",
    "    n_1_solutions = torch.count_nonzero(spheres_1_solution_indices)\n",
    "    see(\"n_1_solutions\", n_1_solutions)\n",
    "    n_0_solutions = torch.count_nonzero(spheres_0_solution_indices)\n",
    "    see(\"n_0_solutions\", n_0_solutions)\n",
    "    \n",
    "    # compute the square root of the discriminant of the quadratic equation\n",
    "    # sqrt(discriminant) = sqrt(B^2 - 4 * C)\n",
    "    # note that there are two solutions to the square root if discriminant is > 0\n",
    "    # we accomodate for that by using + and - sign in subsequent formula\n",
    "    discriminants_sqrt = discriminants.clone()\n",
    "    discriminants_sqrt[spheres_2_solution_indices] = torch.sqrt(discriminants[spheres_2_solution_indices])\n",
    "    discriminants_sqrt[spheres_1_solution_indices] = 0.0\n",
    "    discriminants_sqrt[spheres_0_solution_indices] = -1.0\n",
    "    see(\"discriminants_sqrt\", discriminants_sqrt, False)\n",
    "    assert is_float_tensor_on_device(discriminants_sqrt)\n",
    "    assert discriminants_sqrt.shape == (n_rays, n_spheres)\n",
    "    \n",
    "    # compute the distances from the eye to the intersections\n",
    "    # t_0 = (- B - sqrt(B^2 - 4 * C)) / 2 = -0.5 * (B + sqrt(B^2 - 4 * C))\n",
    "    # t_1 = (- B + sqrt(B^2 - 4 * C)) / 2 = -0.5 * (B - sqrt(B^2 - 4 * C))\n",
    "    t_0s = minus_zero_dot_five * (b + discriminants_sqrt)\n",
    "    t_0s[spheres_0_solution_indices] = 0.0\n",
    "    see_more(\"t_0s\", t_0s, False)\n",
    "    assert is_float_tensor_on_device(t_0s)\n",
    "    assert t_0s.shape == (n_rays, n_spheres)\n",
    "    t_1s = minus_zero_dot_five * (b - discriminants_sqrt)\n",
    "    t_1s[spheres_0_solution_indices] = 0.0\n",
    "    see_more(\"t_0s\", t_0s, False)\n",
    "    see_more(\"t_1s\", t_1s, False)\n",
    "    assert is_float_tensor_on_device(t_1s)\n",
    "    assert t_1s.shape == (n_rays, n_spheres)\n",
    "    \n",
    "    # note that in case a sphere would be completely or partially behind the camera\n",
    "    # we would need to cull away all intersections behind the camera\n",
    "    # by setting them to far or infinity before taking the minimum\n",
    "    \n",
    "    # note that the 1 solution case is rare\n",
    "    # and corresponding values in t_0s and t_1s equal\n",
    "    # in that case the minimum function will simply use that value\n",
    "    \n",
    "    ts = torch.minimum(t_0s, t_1s)\n",
    "    ts[spheres_0_solution_indices] = 0.0\n",
    "    see_more(\"ts\", ts, False)\n",
    "    assert is_float_tensor_on_device(ts)\n",
    "    assert ts.shape == (n_rays, n_spheres)\n",
    "    \n",
    "    # determine the minimum t for each ray\n",
    "    #ts[spheres_0_solution_indices] = far + 10.0\n",
    "    ts[spheres_0_solution_indices] = far + 10.0\n",
    "    ts_minimum = torch.min(ts, dim=1)\n",
    "    ts_min = ts_minimum.values\n",
    "    ts_background_mask = ts_min > far\n",
    "    assert ts_background_mask.shape == (n_rays,)\n",
    "    ts_foreground_mask = ts_min <= far\n",
    "    assert ts_foreground_mask.shape == (n_rays,)\n",
    "    ts_foreground_mask_with_0 = ts_foreground_mask.clone()\n",
    "    ts_foreground_mask_with_0[0] = True\n",
    "    ts_min[ts_background_mask] = 0.0\n",
    "    see_more(\"ts_min\", ts_min)\n",
    "    assert is_float_tensor_on_device(ts_min)\n",
    "    assert ts_min.shape == (n_rays,)\n",
    "    \n",
    "    # compute intersection points\n",
    "    # by scaling each primary ray unit vector by the corresponding minimum t\n",
    "    points_hit = torch.mul(primary_ray_vectors_unit, torch.unsqueeze(ts_min, dim=1))\n",
    "    points_hit[ts_background_mask] = zero_vector_float\n",
    "    see_more(\"points_hit\", points_hit)\n",
    "    assert points_hit.shape == (n_pixels, 3)    \n",
    "    \n",
    "    # for each ray note the index of the sphere that the ray hit\n",
    "    #ts_min_spheres_index = torch.remainder(ts_minimum.indices, n_spheres)\n",
    "    spheres_index_hit = torch.remainder(ts_minimum.indices, n_spheres)\n",
    "    see_more(\"ts_min_spheres_index\", spheres_index_hit)\n",
    "    assert is_long_tensor(spheres_index_hit)\n",
    "    assert ts_min.shape == (n_rays,)\n",
    "    \n",
    "     # for each ray get the center of the sphere that the ray hit\n",
    "    spheres_center_hit = spheres_center[spheres_index_hit]\n",
    "    see(\"spheres_center_hit\", spheres_center_hit)\n",
    "    assert is_float_tensor_on_device(spheres_center_hit)\n",
    "    assert spheres_center_hit.shape == (n_rays, 3)\n",
    "    \n",
    "    # also compute surface normal at each intersection in terms of a unit vector\n",
    "    surface_normals_hit = points_hit - spheres_center_hit\n",
    "    surface_normals_hit[ts_background_mask] = zero_vector_float\n",
    "    surface_normals_hit_unit = tf.normalize(surface_normals_hit)\n",
    "    see_more(\"surface_normals_hit_unit\", surface_normals_hit_unit)\n",
    "    assert is_float_tensor_on_device(surface_normals_hit_unit)\n",
    "    \n",
    "    # sanity check\n",
    "    surface_normals_hit_unit_norm = torch.norm(surface_normals_hit_unit, p=2, dim=1, keepdim=True)\n",
    "    see_more(\"surface_normals_unit_norm\", surface_normals_hit_unit_norm, False)\n",
    "    assert is_float_tensor_on_device(surface_normals_hit_unit_norm)\n",
    "    assert torch.allclose(surface_normals_hit_unit_norm[ts_foreground_mask], one_dot_zero)\n",
    "    assert torch.allclose(surface_normals_hit_unit_norm[ts_background_mask], zero_vector_float)    \n",
    "    \n",
    "    background_mask = ts_background_mask\n",
    "    foreground_mask = ts_foreground_mask\n",
    "    foreground_mask_with_0 = ts_foreground_mask_with_0\n",
    "    \n",
    "    return points_hit, surface_normals_hit, surface_normals_hit_unit, spheres_index_hit, spheres_center_hit, background_mask, foreground_mask, foreground_mask_with_0\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:18.517971Z",
     "start_time": "2024-06-23T17:59:17.957158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute intersections of primary rays with spheres\n",
    "\n",
    "# make a tensor that contains one copy of eye per sphere\n",
    "eyes_spheres_center = eye.unsqueeze(0).repeat(n_spheres, 1)\n",
    "see(\"eyes_spheres_center\", eyes_spheres_center, False)\n",
    "assert is_float_tensor_on_device(eyes_spheres_center)\n",
    "assert eyes_spheres_center.shape == (n_spheres, 3)\n",
    "\n",
    "# make a tensor that contains one copy of eye per primary ray\n",
    "eyes_pixels = eye.unsqueeze(0).repeat(n_pixels, 1)\n",
    "assert is_float_tensor_on_device(eyes_pixels)\n",
    "assert eyes_pixels.shape == (n_pixels, 3)\n",
    "see(\"eyes_pixels\", eyes_pixels, False)\n",
    "\n",
    "points_hit, surface_normals_hit, surface_normals_hit_unit, spheres_index_hit, spheres_center_hit, background_mask, foreground_mask, foreground_mask_with_0 = intersect_rays_with_spheres(n_pixels, n_spheres, eyes_spheres_center, spheres_center, spheres_radius)\n",
    "\n",
    "print(f\"spheres_index_hit[middle_pixel_index]={spheres_index_hit[middle_pixel_index]}\")\n",
    "\n",
    "print(f\"spheres_center_hit[middle_pixel_index]={spheres_center_hit[middle_pixel_index]}\")\n",
    "\n",
    "print(f\"points_hit[middle_pixel_index]={points_hit[middle_pixel_index]}\")\n",
    "\n",
    "print(f\"surface_normals_hit[middle_pixel_index]={surface_normals_hit[middle_pixel_index]}\")\n",
    "\n",
    "print(f\"surface_normals_hit_unit[middle_pixel_index]={surface_normals_hit_unit[middle_pixel_index]}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.shape=torch.Size([2073600, 4])\n",
      "b=\n",
      "tensor([[-10.8561,  -9.7783, -23.6230, -23.0668],\n",
      "        [-10.8593,  -9.7840, -23.6299, -23.0735],\n",
      "        [-10.8624,  -9.7898, -23.6367, -23.0802],\n",
      "        ...,\n",
      "        [ -8.0470, -18.5743, -23.6367,  -0.5566],\n",
      "        [ -8.0446, -18.5718, -23.6299,  -0.5564],\n",
      "        [ -8.0423, -18.5694, -23.6230,  -0.5562]])\n",
      "torch.norm(c)=368.54443359375\n",
      "c.shape=torch.Size([4])\n",
      "c=tensor([ 64., 127., 300., 160.])\n",
      "n_2_solutions=1264526\n",
      "n_1_solutions=4\n",
      "n_0_solutions=7029874\n",
      "torch.norm(ts_min)=10057.7109375\n",
      "ts_min.shape=torch.Size([2073600])\n",
      "ts_min=tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "ts_min.min()=0.0\n",
      "ts_min.mean()=4.429181098937988\n",
      "mean_ignoring_zero(ts_min)=10.468738555908203\n",
      "ts_min.median()=0.0\n",
      "ts_min.max()=17.314985275268555\n",
      "points_hit.shape=torch.Size([2073600, 3])\n",
      "points_hit=\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "points_hit.min()=-9.33489990234375\n",
      "points_hit.mean()=1.1929091215133667\n",
      "mean_ignoring_zero(points_hit)=tensor([-0.8045, -0.0866,  9.3497])\n",
      "points_hit.median()=0.0\n",
      "points_hit.max()=14.995218276977539\n",
      "ts_min_spheres_index=tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "ts_min_spheres_index.min()=0\n",
      "ts_min_spheres_index.mean()=0.6688744425773621\n",
      "mean_ignoring_zero(ts_min_spheres_index)=1.6415436267852783\n",
      "ts_min_spheres_index.median()=0\n",
      "ts_min_spheres_index.max()=3\n",
      "spheres_center_hit.shape=torch.Size([2073600, 3])\n",
      "spheres_center_hit=\n",
      "tensor([[-1.,  0.,  8.],\n",
      "        [-1.,  0.,  8.],\n",
      "        [-1.,  0.,  8.],\n",
      "        ...,\n",
      "        [-1.,  0.,  8.],\n",
      "        [-1.,  0.,  8.],\n",
      "        [-1.,  0.,  8.]])\n",
      "surface_normals_hit_unit.shape=torch.Size([2073600, 3])\n",
      "surface_normals_hit_unit=\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "surface_normals_hit_unit.min()=-0.9999997019767761\n",
      "surface_normals_hit_unit.mean()=-0.1048995777964592\n",
      "mean_ignoring_zero(surface_normals_hit_unit)=tensor([-0.0425,  0.1023, -0.8035])\n",
      "surface_normals_hit_unit.median()=0.0\n",
      "surface_normals_hit_unit.max()=0.9999935626983643\n",
      "spheres_index_hit[middle_pixel_index]=1\n",
      "spheres_center_hit[middle_pixel_index]=tensor([ 2., -2., 12.])\n",
      "points_hit[middle_pixel_index]=tensor([ 4.8863e-03, -4.8851e-03,  7.8722e+00])\n",
      "surface_normals_hit[middle_pixel_index]=tensor([-1.9951,  1.9951, -4.1278])\n",
      "surface_normals_hit_unit[middle_pixel_index]=tensor([-0.3990,  0.3990, -0.8256])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:18.532267Z",
     "start_time": "2024-06-23T17:59:18.520026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spheres_rgb_hit = spheres_rgb[spheres_index_hit]\n",
    "see(\"spheres_rgb_hit\", spheres_rgb_hit)\n",
    "assert spheres_rgb_hit.shape == (n_pixels, 3)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spheres_rgb_hit=tensor([[150,  90, 200],\n",
      "        [150,  90, 200],\n",
      "        [150,  90, 200],\n",
      "        ...,\n",
      "        [150,  90, 200],\n",
      "        [150,  90, 200],\n",
      "        [150,  90, 200]], dtype=torch.int32)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:59:18.893228Z",
     "start_time": "2024-06-23T17:59:18.534051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_rgb = spheres_rgb_hit.clone()\n",
    "img_rgb[background_mask] = zero_vector_int\n",
    "img_rgb_view = img_rgb.view(resx_int_py, resy_int_py, 3)\n",
    "img_rgb_view_permuted = img_rgb_view.permute(1, 0, 2)\n",
    "assert img_rgb_view_permuted.shape == (resy_int_py, resx_int_py, 3)\n",
    "plt.imshow(img_rgb_view_permuted)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12ea8c530>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAFICAYAAABOaMReAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABSIUlEQVR4nO3dd3wUdf7H8ddsem9ACgQIKGAAkSIhUixEqljAgnCgHuqhoIftEAueDRTPAqeC+lPhbCh3IogI0hEMAQJID0UgtCRAyCYB0na/vz+GrCwECGQ3s+XzfDzmAezM7n5mMyTvfOdbNKWUQgghhBDCjZiMLkAIIYQQ4lJJgBFCCCGE25EAI4QQQgi3IwFGCCGEEG5HAowQQggh3I4EGCGEEEK4HQkwQgghhHA7EmCEEEII4XYkwAghhBDC7UiAEUIIIYTbcekA88EHH9C4cWMCAwNJSUlh9erVRpckhBBCCBfgsgHm22+/5cknn+Sll15i3bp1tGnThp49e5KXl2d0aUIIIYQwmOaqizmmpKRw7bXX8v777wNgtVpJTEzkscce49lnnzW4OiGEEEIYydfoAqpSVlZGZmYmY8aMsT1mMplIS0sjPT29yueUlpZSWlpq+7fVaiU/P5+YmBg0TXN6zUIIIYSoOaUURUVFJCQkYDKd/0aRSwaYo0ePYrFYiI2NtXs8NjaW7du3V/mc8ePH8/LLL9dGeUIIIYRwsv3799OgQYPz7nfZPjCXasyYMZjNZtuWnZ1tdElCCCGEuExhYWEX3O+SLTB16tTBx8eH3Nxcu8dzc3OJi4ur8jkBAQEEBATURnlCCCGEcLKLdf9wyRYYf39/2rdvz6JFi2yPWa1WFi1aRGpqqoGVCSGEEMIVuGQLDMCTTz7JfffdR4cOHejYsSPvvfceJ06c4IEHHjC6NCGEEEIYzGUDzD333MORI0cYO3YsOTk5XHPNNcybN++cjr1CCCGE8D4uOw9MTRUWFhIREWF0GUIIIYS4DGazmfDw8PPud8k+MEIIIYQQFyIBRgghhBBuRwKMEEIIIdyOBBghhBBCuB0JMEIIIYRwOxJghBBCCOF2JMAIIYQQwu1IgBFCCCGE25EAI4QQQgi3IwFGCCGEEG5HAowQQggh3I7LLuYohPB8JpMJk8lESEgIYWFhmEwmWrRoQWBgIAB+fn507NgRf3//ar9maWkpa9asoby8HIBTp06RlZWF1WqlsLCQkydPYrVasVqtTjknIUTtkAAjhHA6Hx8foqOjqVu3Lg0aNKBZs2YkJCTQuHFjGjZsSExMjG2l+bCwMHx8fOyer2latd/r7PVpLRYLRUVFAOTk5JCfn092djZ79+7l4MGD7Ny5k/3793P06FHy8/OxWCw1PFshRG2Q1aiFEA7l6+tLREQETZs2pWXLlrRu3Zq2bdvSrFkzQkNDCQ0NRdO0SwolzqKUQilFcXExRUVF7Nixg/Xr17Np0ya2bt3K7t27MZvNVFRUGF2qEF7nYqtRS4ARQtRIYGAgCQkJXHPNNXTt2pXWrVvTvHlz6tSpg7+/PyaT+3W1s1qtlJWVcfToUbZv387GjRtZsWIFGzZs4NChQ5SWlhpdohAeTwKMEMKhTCYT9erVo1WrVvTt25dOnTpx5ZVXEhkZec6tH09isVgoKChgx44drFq1ip9++oktW7aQl5cn/WmEcAIJMEKIGvP19aVx48akpaXRvXt3OnXqRGxsLL6+vi5xK6i2KaWoqKggJyeHVatWsWjRIhYuXMi+ffvkdpMQDiIBRghxWSpDy1133cX1119Phw4diIqKcstbQs5mtVo5fvw4a9asYdmyZcyYMUPCjBA1JAFGCFFtJpOJxMREevXqxW233UbHjh2Jjo72ylaWy6WUIj8/n4yMDGbNmsW8efPYv3//OaOjhBAXJgFGCHFR4eHhdO3alYEDB3LjjTeSkJAgocUBlFIcPHiQJUuWMH36dFasWEFhYaHRZQnhFiTACCGqpGkajRs3ZuDAgdx77700b94cPz8/CS5OoJSirKyMrKwsvvnmG6ZPn86+ffukVUaIC5AAI4Sw4+PjQ7t27Rg+fDi9evUiPj5eQkstUkpx6NAh5s2bx5QpU1i/fr1MnidEFSTACCEACAoKokePHjzwwAPceOONhIWFSXAxkFKKoqIilixZwqeffsrChQs5deqU0WUJ4TIkwAjh5YKCgrj55psZNWoU1113HQEBAUaXJM5SWlrKypUree+99yTICHGaBBghvNSZwaVz586XtCCiMIYEGSH+JAFGCC/j6+tLz549efLJJ+nSpYt0zHUzlR1+V6xYwTvvvMP8+fOlj4zwShJghPASPj4+tG3blr///e/079+foKAgCS5uTCnFyZMn+d///sekSZNYv369LFkgvIoEGCG8QOPGjXnkkUcYPny4dM71MEopCgsLmTx5MlOmTGHfvn1GlyRErZAAI4QHCwsLY9CgQTz33HMkJiZKcPFgSimys7N5/fXX+eabbyguLja6JCGcSgKMEB7IZDLRrl07xo8fz4033ujRq0ALexaLhcWLF/Pss8+yYcMGua0kPNbFAoysyiaEm4mJieH1119nwYIFdO/eXcKLl/Hx8SEtLY2FCxfy6quvEh0dbXRJQhhCWmCEcBMmk4nrr7+eN998k/bt28uq0AKr1cqaNWsYPXo0v/76q7TGCI8iLTBCeIDKVpeZM2fSoUMHCS8C0ENtx44dmTVrlrTGCK8jLTBCuDBN02jfvj0ffvihtLqIC6psjXn00UdZv369LBQp3J60wAjhpgICAnjyySeZO3eutLqIi6psjfn5558ZNWqULBkhPJ60wAjhghISEnjnnXfo378/fn5+Rpcj3Ex5eTkzZszg6aef5vDhw0aXI8RlkRYYIdyIpml07NiRX375hbvvvlvCi7gsfn5+3HvvvcyfP58OHTrI/EDCI0mAEcJF+Pj4MGTIEGbPnk1ycrL80BE1omkarVq14scff2TQoEEy3F54HAkwQriA4OBg3njjDT788ENiY2MlvAiH0DSNuLg4pkyZwrhx4wgODja6JCEcRvrACGGw+Ph4PvroI3r37o2vr6/R5QgPVVFRwU8//cTw4cPJyckxuhwhLkr6wAjhwpKTk/nyyy+55ZZbJLwIp/L19eXWW2/liy++4KqrrjK6HCFqzOEBZvz48Vx77bWEhYVRr149br/9drKysuyOKSkpYcSIEcTExBAaGsqAAQPIzc21OyY7O5u+ffsSHBxMvXr1eOaZZ6ioqHB0uUIYplOnTsyZM4cbb7xRbhmJWqFpGt27d2fOnDl07NjR6HKEqBGHB5hly5YxYsQIVq1axYIFCygvL6dHjx6cOHHCdswTTzzBjz/+yIwZM1i2bBmHDh2if//+tv0Wi4W+fftSVlbGb7/9xrRp05g6dSpjx451dLlC1DqTyUT//v35+uuvady4sYQXUas0TSMpKYlvvvmGO+64Q+YXEu5LOVleXp4C1LJly5RSShUUFCg/Pz81Y8YM2zHbtm1TgEpPT1dKKTV37lxlMplUTk6O7ZjJkyer8PBwVVpaWq33NZvNCpBNNpfaTCaTGjZsmCosLHTg/zIhLk9hYaF64IEHlMlkMvz/hmyynb2ZzeYLXr9Oj95msxnAtkZHZmYm5eXlpKWl2Y5p0aIFDRs2JD09HYD09HRat25NbGys7ZiePXtSWFjIli1bqnyf0tJSCgsL7TYhXInJZOL+++/n3XffJSwszOhyhCAsLIyJEycydOhQaYkRbsepV6zVamXUqFF07tyZVq1aAZCTk4O/vz+RkZF2x8bGxtp6xufk5NiFl8r9lfuqMn78eCIiImxbYmKig89GiMtXGV7ee+89CS/CpYSFhTFp0iQJMcLtOPVqHTFiBJs3b2b69OnOfBsAxowZg9lstm379+93+nsKUR0mk4n77rtPwotwWZUtMUOGDJEQI9yG08Ztjhw5kjlz5rB8+XIaNGhgezwuLo6ysjIKCgrsWmFyc3OJi4uzHbN69Wq716scpVR5zNkCAgJk8TLhcirDy8SJEyW8CJcWHh7OpEmTAPjiiy+wWq0GVyTEhTk8aiulGDlyJDNnzmTx4sUkJSXZ7W/fvj1+fn4sWrTI9lhWVhbZ2dmkpqYCkJqayqZNm8jLy7Mds2DBAsLDw0lOTnZ0yUI4hYQX4W4qQ4y0xAi34Ohe7Y888oiKiIhQS5cuVYcPH7ZtJ0+etB0zfPhw1bBhQ7V48WK1du1alZqaqlJTU237KyoqVKtWrVSPHj3Uhg0b1Lx581TdunXVmDFjql2HjEKSzcjNZDKp+++/X0YbCbdkNpvV0KFDlaZphv9fks17t4uNQnJ4gDlfIZ9//rntmFOnTqlHH31URUVFqeDgYHXHHXeow4cP273O3r17Ve/evVVQUJCqU6eOeuqpp1R5eXm165AAI5uR23333SfhRbg1s9mshgwZYvj/Jdm8d7tYgJG1kIRwsI4dOzJz5kwSEhKMLkWIGjl48CC33347a9euNboU4YVkLSQhalGHDh34+uuviY+PN7oUIWosISGBb775hnbt2hldihDnkAAjhIPExsYyceJEmjRpIssDCI+gaRpNmzZl4sSJ1KtXz+hyhLAjAUYIB4iKimLatGmkpqZKeBEeRdM0OnfuzNSpU8+ZgFQII0mAEaKGAgICeP7557n55pslvAiPpGkaPXr04LnnnsPf39/ocoQAJMAIUSOapjFo0CAee+wxmTdDeDQfHx8ef/xx7r33XgnqwiXId1whaqBbt268/fbb8lup8AoBAQG88847dO7c2ehShJAAI8TlSkhI4P3335d+AcKrREVF8cEHH8hIO2E4CTBCXIawsDA+/PBDWrZsKc3pwqtomkarVq14//33CQ0NNboc4cUkwAhxiTRN429/+xt9+/aV8CK8kslk4tZbb+XBBx+U/wPCMBJghLhE119/PWPGjMHX12mLuQvh8nx9fXnhhRfo0qWL0aUILyUBRohLEBMTw5tvvklUVJTRpQhhuOjoaCZMmEB0dLTRpQgvJAFGiGry9fXl9ddfp0OHDtJsLgT67dSOHTvy6quvSoukqHUSYISopn79+jF06FCZ70WIM5hMJu6//3569+5tdCnCy8h3YiGqoX79+rz++usEBQUZXYoQLic4OJhx48bJ0GpRqyTACHERvr6+vPjii7Ro0cLoUoRwWS1btuSFF17Ax8fH6FKEl5AAI8RF9OjRgyFDhki/FyEuQNM07r//frp37250KcJLSIAR4gKioqIYO3as3DoSohqCgoJ46aWXZHZqUSskwAhxHpqm8cADD8ioIyGqSdM0UlJSGDp0qNGlCC8gAUaI82jatClPPfWU3NMX4hL4+PjwzDPP0KRJE6NLER5OAowQVfDx8WHs2LEyqkKIy1C/fn3p0CucTgKMEFXo2bMn/fv3l1tHQlwGTdO46667SEtLM7oU4cEkwAhxlqCgIJ5++mmCg4ONLkUItxUSEsLTTz9NYGCg0aUIDyUBRoiz9O/fn+uuu05aX4SoAU3T6Nq1K7fffrvRpQgPJQFGiDPExMQwZswYAgICjC5FCLcXEBDAc889J4ufCqeQ1beEOMM999wjM+6K81Oq8i9gKYXyE3/uO5kLp46e/7nhjcEvRP+7yQf8I07v0MCDW/uSk5O5++67+eijj4wuRXgYTSnb/0iPUlhYSERExMUPFOK06Oholi9fTsuWLY0uRRhNKUDpAaX0OBQfgqO/Q1mR/mfJcT2sFO//8znlxfaB5mwBUeDjr//dNxAim4NmgsimEJoIYYl6yAlJgIDI02HHM8LNpk2buP766zl+/LjRpQg3YjabCQ8PP+9+aYER4jRpffFSlb/DVZyComwo2AHHNkPuWji2RQ8wpcfBagFq8PteyVmtM+Y/7P+tmUDz0YNOYBREJ0NUM4hpDXVaQ1gj8A/DHUONtMIIZ5AWGCGQ1hevoxRYy/SWlcO/wcHlkJMBhXv0VhRlMbrCM5jANwBCG0Dda6BuW4i/DqJbQFBdPfi4AWmFEZdKWmCEqAZpffECSkFZIRzZoIeWvXMhfzuUHKNGLStOZ9Vbhwp26tvOGWDyh5A4iO8MiTdC/W4Q1hB8Al22dSY5OZm77rqLjz/+2OhShIeQFhjh9YKCgli0aBGpqalGlyIcTSkoL4K89fDHbNg3Dwp26a0vHkPTby3FtIKkftC4F0Q1d8kws2LFCm6++WZKSkqMLkW4gYu1wEiAEV7vlltu4b///a8MnfYUSum3gPK3wd6fYMd3el8WjwotF+AXAnXaQJN+0LiP3pdG83GJMFNaWsodd9zBzz//bHQpwg1IgBHiAgIDA5kzZw433XSTTFzn7pTSO9seXAZbPtf7tZSZja7KWP4RUL8rJP8VGlyvdxA28DpXSrFw4UL69etHaWmpYXUI9yABRogLuPbaa1myZAkhISFGlyIul1JQtA92/he2f6G3trhUJ1wXoPnot5Wu6A/N7oGoFoa1yhQXF3PDDTeQmZlZ6+8t3It04hXiPDRNY/DgwbLmkbuqDC5bPoWtn0PxQaMrcl3KAvlbYfVW2DAJmtwGrf8G9dqCT1CtBpmQkBAGDx4sAUbUmLTACK/VqFEjVqxYQYMGDYwuRVwKZdX7t/z+PuyZA8UHjK7IPfkE6sOx246Cht3Bt/aCfHZ2Nl26dGH//v0XP1h4rYu1wLjHBAJCOEGfPn2oX7++0WWI6lJWKNwLq16CmTfDpikSXmrCUgIHFsNPd8KsfvDHj/pw7Vr4nTYxMZHevXs7/X2EZ5MAI7xSQEAA/fv3l4677kApOJEDq/4JM7rC6tfgxGGjq/Ic1rI/g8zsfrDvZ7BWOPUtNU1jwIABMvJP1IjcQvJQJiAUCAKaAGGn/92O6qfWAuB3wAJkAaWnHyvHtaf9qo4OHTqwdOlS6bzrytTpBRN3/Q/WvgnHNhldkXfwDYYr74Q2j+sz/5p8nPI2J06coFu3bqxbt84pry/cn3Ti9QImIBq4ErgaaA20AOKBukA44Hf6WO30Vh3qjK0AqAB2AweBTcBG9IBzBLjAEnYuaejQodJ515VZLXpgSX8RshfoQUbUjoqTsO0/sPsHuPpRaDNSX2DSwa2VwcHBDBkyRAKMuGzSAuOGTEAUekjpCVwLJANx6Im0Nu4LKsAKHEcPNGuAX4HlwGH01hpXFRkZyapVq2jevLnRpYizKaXP3bL+PX20TKmsm2O46GTo8A+48h59FW0H2rZtG6mpqZjNXj5fj6iS4Z1433jjDTRNY9SoUbbHSkpKGDFiBDExMYSGhjJgwAByc3PtnpednU3fvn0JDg6mXr16PPPMM1RUOPe+rCszAQ2AQcC3wDpgMfAC0AtoCPhTe52aNMAHqAO0AR4EPkcPMguB0egtQa54h7tDhw4kJSUZXYY4m7LoaxTNugVWvyrhxVXkb4WFD8Mv9+trMTnwd96mTZvSrl07h72e8C5O/Xm3Zs0aPvroI66++mq7x5944gl+/PFHZsyYwbJlyzh06BD9+/e37bdYLPTt25eysjJ+++03pk2bxtSpUxk7dqwzy3VJkcAtwHRgNfAf4E7+DCyu1AXVhB5ougDjgRXAAuAfQDP0wOMK+vXrh7+/v9FliEpKQWmB3jl3dj84vFIfcSRch7UMdn4L36fB+nehrMghL+vv78+tt97qkNcS3sdpt5CKi4tp164dH374Ia+99hrXXHMN7733Hmazmbp16/L1119z5513ArB9+3auuuoq0tPT6dSpEz///DO33HILhw4dIjY2FoApU6YwevRojhw5Uq0fPu58C0kDGgFD0cNKC/7sw+KOFHAUWAp8AKzFuD4zkZGRpKeny8rTrkIpyEmHFaPh0Ercv3u4F9B89InwurwBEVfUuG/M1q1bue666+Q2kjiHYbeQRowYQd++fUlLS7N7PDMzk/LycrvHW7RoQcOGDUlPTwcgPT2d1q1b28ILQM+ePSksLGTLli3OKtlwPkAHYCJ668U/0W/DuHN4AT2Q1UUPY/OAX4C7ASPG/7Rv354mTZoY8M7iHJYyfS6XH++AQyuQ8OImlAV2fw/f3wzb/6N/HWtAbiOJy+WUUUjTp09n3bp1rFmz5px9OTk5+Pv7ExkZafd4bGwsOTk5tmPODC+V+yv3VaW0tNRucbDCwsKanEKt0tD7kTwJ3IY+5NmVbg05igYEAqnoHY/XoIe1n6i9Fplbb70VPz93j4RuTik4dQRWPgtZX8sII3dVtA8WPgQ5q6HTyxAYc1mtMZW3kZYsWeKEIoUnc3gLzP79+/n73//OV199RWCgY3usX8j48eOJiIiwbYmJibX23jVRH3gVmA/8BX3IsyeGlzNp6K1KqcCX6K0y3XD+mP7Q0FDS0tJk8jojKaUvtjirD2ydKuHF3VnLYeNk+PFWOLLhsvouaZpGWlqazMkkLpnDA0xmZiZ5eXm0a9cOX19ffH19WbZsGZMmTcLX15fY2FjKysooKCiwe15ubi5xcXEAxMXFnTMqqfLflcecbcyYMZjNZtvm6mtsBAD3o99OeQ6oh+cHl7NVBpnO6K0w04CmTny/K6+8koYNGzrxHcQFWSvgj9nwQy/Iy0RuGXkKBYfTYVZvfUXwy5jFt3HjxlxxxRVOqE14MocHmO7du7Np0yY2bNhg2zp06MDgwYNtf/fz82PRokW252RlZZGdnU1qaioAqampbNq0iby8PNsxCxYsIDw8nOTk5CrfNyAggPDwcLvNVV2JPppoCvr8Ld4WXM6moc8SfC/6qKWhOGf49U033SS/5RnFUgZr34D5Q+CErBrtkU7mwsK/QsbLesvaJYwPCQkJ4cYbb3RiccITObzVPiwsjFatWtk9FhISQkxMjO3xYcOG8eSTTxIdHU14eDiPPfYYqampdOrUCYAePXqQnJzMkCFDmDBhAjk5ObzwwguMGDHCrdfO8AMGo3fObYgEl7NpQBLwCfoEfS8CfzjotU0mE127dpXbR0YoydfDy/qJ+nBc4bnKT+jLPhTthy4TILhetZ6maRpdu3Zl4sSJeOjcqsIJDFnM8d133+WWW25hwIABdOvWjbi4OL7//nvbfh8fH+bMmYOPjw+pqan85S9/YejQobzyyitGlOsQMcAk9FaXRkh4uRB/9NaY+UBfHHOR1q1bV0Y6GKHkmN7RM/NfEl68hbUctk2DBX+Fwuxqt8S0b9+eunXrOrk44UlkKYFa0BL4P6Ajsvz3pVBAMfpsw58Ap2rwWj169OCnn37C11eW/6oVSsHJw7DkMdg9E+nv4qWiroJeX+mLQl6k9bOiooLevXuzcOHC2qlNuDzDlxLwZhpwOzAHSEE+7EuloQ8pfxt4E31l7cuVkpKCj4+rzAXs4ZSC/C3wQ28JL97u+Db4eeDpEUoXvg58fHzo2LFj7dQlPIL8THWSyvDyf0Bj5JZRTfgCj6Dffku4jOebTCbat28v/V9qg1L62jlzB8LRjUh4ERTsgJ/vhj0/XnCYtaZptG/fHpNJfiyJ6pH2dCfQ0Cek+wS974uoOV9gCJCIPl/OoUt4blRUFG3atHFKXd5KKYXVoqgos1J8tIyKMv0H04n8U5gyJhJUqIBk/EynCPHPw8+nBA1LTWedF+6qYBfMHwo3TYZm94BWdUi55ppriIiI4PhxWchTXJwEGAerDC//h4QXR9OAG9AnvxsCVHcwbvPmzc87f5CoPqUUpScs5O0u5vCOInJ2FFOYV0JJUQXWCr2lRVkVqPvRtPsA8NFKCfQtJCIwm/iw34kL/Z26IVn4+xRLmPE2ZWZY/AigoNnAKkNMQkICzZo1IyMjo/brE25HAowDSXhxvsoQMwF4kOp17G3RooVbD783mqXCSv6BU2xbkseBTWaKjpZhtVzo1pCPrbuDVflSXhZCUVk8Bwo7YtIqiAg4QGLEKpKilhEbuhkf06VPfCbcVJkZFj+qh5cr7zmnY6+/vz8tWrSQACOqRQKMA12H3DaqDRr6YpBHgNHAxSajb9u2rfR/uQxWi+LgFjO//5xD7s5iyk5ZaviKGlblx/GSJI6XJLEl7w4aRKzh6rjpxIduxMdU7pC6hYsrM8Ovz0Bk83NGJ5lMJtq2bcu0adOMq0+4DQkwDtIE+BAJL7WlsmPvZuAz4HxdA/38/GT+l0uklKL4aBlrfzjI7vRjlJde+vo21WFRgewr6MIB87UkRf1KxwYfER5wQG4teYPiAzDvXug9Heq0sQsxlcvQVFRIy5y4MOnu7QAh6Lc0WiOjjWqTP/AW0PUCx8TExJCUlFRLFbk/S7mVXavymT1+G9uXHnFaePmThkUFsis/jdnb/03W0T5YrLJauFc4nqUPsT660W6IddOmTYmJkV8FxcVJgKkhE/A4et8XCS+1LwL4gPMPr46JiSEsLKwWK3JPSinKTlaQ/k02S6bspjC3tleJ1igui2fZ3jGszB7FqfKIS1lKR7ir41mw9DF9xubTX/CwsDCio6MNLky4AwkwNXQd8A/kXpxRNPQFMV+k6q9Bs2bNZAHHi1BKceJ4OfMn7mTzL7lYKoxLDlblx5a8/izZ8wIlFRJivMKhFbBwmN43BggNDaVZs2YGFyXcgQSYGggBngciDa7D22noK1j3rWJf69ata7ka91IZXhZ9uIsDmwtdJDBo7CvoYgsxwtMp+GMOrJ2gr1oO5ywILERVJMDUwJ1AmtFFCACCgWeB0LMej42NlRFIF1B6wsLiybs5tK3I6FLO8meIOVUuIcbzWWHdv2DTR2goYmNjjS5IuAEJMJepPjAWuXXkSjqgzw1Tyc/PT2bgvYCKMitr/neAg9sKjS7lPPQQs2Lf01RIx17PZy2HjJfh8G9cc801+PnJ11xcmASYy3Q/+hpHwnX4AiOByjl3/fz8LriSqTdTSrFj5VG2Lspz8eWKNP44fgNbcu90kdtbwqlKjsHiRwlXR2XleHFREmAuQwL6b/ry4bmeJODe03+Pi4ujYcOGRpbjkpRSHNt3ktXf7b/IjLquwar8WHd4KEdPNje6FFEbjm2i0YEPiYs5+4awEPbkZ/Bl6AnIj0XXZEKfpTcUfVZPHx8fgytyPdYKReasQ5wqdJ+JwkoqIll94GGZI8ZLhOYupF+TI0aXIVycBJhLFII+A6x8cK6rPXAj+hDqwMBAo8txKUop9q47zt5Md1vtV+NAYUd25XeXW0lewNcEz98MnWUOSnEB8nP4El0NyAA/1+YL3AFER0ZKC8xZKkqtbJyX4xa3js5mVX5szBlImUXm9fEG9cJgwq0QGWR0JcJVSYC5RLcA8ju9a9PQW2DqSXg5x/5NZvJ2nzC6jMt27OSV7DenSiuMl+jUCEZdDyaZCUFUQQLMJQgF+iBLBriDBsAIWcTRjrIqdmfku2XrSyWFDzuO9cKqZISKNzCZ4PFukNrY6EqEK5IAcwkaAU2NLkJUiy/QZPt2CZtnKDxSysGtrjrnS/UdLmpDUen5Vr8SniYyCN7sJ7eSxLkkwFyCDpw706twYatXw6lTRlfhMnJ3FXPKXG50GTVWZgnlYFE7uY3kJTQNOjWGkRdadl54JQkwl6C90QWIS3PgABw9anQVLkFZFfvWFxhdhoNoHC66xugiRC3yMcGjXaB1vNGVCFciAaaa/IB2SP8Xt2I2Q16e0VW4hIpyK8cPeU5r1JETLSi3BhtdhqhFcWEw7hYIkO5P4jQJMNXkB8ik9G6mrAw2bDC6CpdQUlhB0ZFSo8twmJPlMZwsjzG6DFGLNA3SmumbECABptrqIbPvuqWTJ5HOEpB/8BTlpyxGl+Ew5ZZgTpbVMboMUcsCfOHVPtKhV+gkwFSThtw+cktr1xpdgUuwlFslxwm3p2lwdQLcKYvMCyTAVJs/EmDc0gn3nbTNkSwVkl6EZ/AxwT+6Q2Kk0ZUIo0mAqaaW6OsgCeGO8nYXG12CEA5zRR14MNXoKoTRJMAIIYRwK5oGD6RAwyijKxFGkgBTTZsBuRkh3FVsU0+bglGhaVajixAGahABw1KMrkIYSQJMNZUD0ovADYV62g/uy2Py9aweXIG+hYQHHDC6DGEgaYUREmCqSSEBxi21l/mTAXz9TWgelGGC/I7j53PS6DKEwRpEQv+rja5CGEUCTDXlAfuMLkJcuuBgPOon92WKSgjCL8jH6DIcpm7INvxMnjOzsLg8mgb3dZR5YbyVBJhqKgeKjC5CXBp/f7jmGqOrcAlB4b6E1w0wugwHsRIftsHoIoSLaBUPt7Q0ugphBAkw1VQOrENuI7mVyEiIjTW6Cpfg42ciqr5n/Joa4FtIQtg6aVgTAPiaYFB7WSPJG0mAuQQyp6ubqV8f6sh08wCaSaNR20ijy3CI2JCthAXkGl2GcCE3XAEdEo2uQtQ2CTCXYC0g04G5kZQUCAw0ugqXUa9pKEERfkaXUUNWkqKWoeE56zqJmgv0hb90kNnSvY0EmEuwD9hldBGiWiqAXc2ayS2/M4TXDaB+S/deUz0i4CCNo5bL7SNhR9OgTzIkRBhdiahNEmAuwQlgLtIPxh3sBz5ct87oMlyKZtJomhKNycddf/orGkctJ8j3uNGFCBfUIBJ6NDe6ClGbJMBcojlAidFFiAtSwGLgiFVmaj1bYnIQsfHuOZ4uxO8IV9WdJa0vokomDQZcA/6eM1uAuAinBJiDBw/yl7/8hZiYGIKCgmjdujVr1/7ZBVYpxdixY4mPjycoKIi0tDR27txp9xr5+fkMHjyY8PBwIiMjGTZsGMXFxvdA2QRsNLoIcUEVwA9AfkEBFov0lTiT74mdXB32Hiat3OhSLpGVq+OmExmYbXQhwoV1awLN6xldhagtDg8wx48fp3Pnzvj5+fHzzz+zdetW3n77baKi/pzvecKECUyaNIkpU6aQkZFBSEgIPXv2pKTkz7aNwYMHs2XLFhYsWMCcOXNYvnw5Dz/8sKPLvWQngMmA/G7vutYCS4AdO3bYXVNeTym0fT/TKGQ+SVHLcJ+boYqY4F00q/OztL6ICwoNgF5XGV2FqC2aUsqh38WeffZZVq5cya+//lrlfqUUCQkJPPXUUzz99NMAmM1mYmNjmTp1KgMHDmTbtm0kJyezZs0aOnToAMC8efPo06cPBw4cICEh4aJ1FBYWEhHhnB5d8cBKIMkpry5qwgo8CUwEmjRpwrp165x2HbgdaznM7IXav5hjp65gzvaJnKqIMbqqi/I1naLnFWNIjFglAUZc1K+74ebJUFphdCWipsxmM+Hh5x944PAWmNmzZ9OhQwfuuusu6tWrR9u2bfnkk09s+/fs2UNOTg5paWm2xyIiIkhJSSE9PR2A9PR0IiMjbeEFIC0tDZPJREZGRpXvW1paSmFhod3mLIeBT5BWGFf0BzD99N9zcnLIzpZbDjZFB+DoRjQNYoJ2k5I42Q1uJVm5qu4sGkSskfAiqqVNfWhW1+gqRG1weID5448/mDx5MldeeSXz58/nkUce4fHHH2fatGmA/kMFIPasGVJjY2Nt+3JycqhXz/5Gpq+vL9HR0bZjzjZ+/HgiIiJsW2Kic2c1mob+w1K4jgpgElA5xVl5eTlms9nAilxMXiaUHANA0xRXxsynVb3/4rpRXBEf9jvX1v8UkyZ9mUT1hAVAamOjqxC1weEBxmq10q5dO8aNG0fbtm15+OGHeeihh5gyZYqj38rOmDFjMJvNtm3//v1Ofb9DwKvoPzSFa1gDfHbGv8vLy9m4UbpcA6CssPcnzuz34msqp0P9z2gQvhbX6w+jiA7axfWN38Dfxz1HTQnj9EkGt50tQFSbwwNMfHw8ycnJdo9dddVVtqb8uLg4AHJz7acCz83Nte2Li4sjLy/Pbn9FRQX5+fm2Y84WEBBAeHi43eZs/wV+cfq7iOo4AYw7/eeZcnJycHA3L/dUXgw5q895OMC3iJuavEx9lwoxipigXfS44gUiA/fJrSNxSTQNrqkPUcFGVyKczeEBpnPnzmRlZdk9tmPHDho1agRAUlIScXFxLFq0yLa/sLCQjIwMUlNTAUhNTaWgoIDMzEzbMYsXL8ZqtZKSkuLoki/bSfQfmjKtlrEU+i29eVXs27x5cy1X46IK90Lhvip3Bfsdo3uTl0mMyHCBKfoV0UG7uVnCi6iB+hHQsZHRVQhnc3iAeeKJJ1i1ahXjxo1j165dfP3113z88ceMGDECAE3TGDVqFK+99hqzZ89m06ZNDB06lISEBG6//XZAb7Hp1asXDz30EKtXr2blypWMHDmSgQMHVmsEUm1KB95AbiUZRQGbgdeo+muQlZXFiRNnt8t4ofxtUFH156BpEOx3lB5XPEfruG/x0UprubhKeniRlhdRU74+0EWGiXo8hy9Afu211zJz5kzGjBnDK6+8QlJSEu+99x6DBw+2HfOPf/yDEydO8PDDD1NQUECXLl2YN28egWcsvPfVV18xcuRIunfvjslkYsCAAUyaNMnR5daYFfgAaA/chSwmVtsKgEfRR4ZVJT8/n6KiIkJDQ2uvKFejFBz67YKHaBr4+5ykU4MPiQvdRMaB4ZhLGlJbV7RGBU2il9Ip8X3C/HMkvIgaS03SZ+UtM7pRUTiNw+eBcRXOnAemKknA90AbJMTUljJgODCV8/fe8PX1ZenSpXTu3LnW6nI5ljL4bzfIqXoKgrMpBcVlsaw7dD87j/Wg3BqM865qRbDfMdolTKVFnTn4+cjEg8Ixcougw9twoMDoSsTlqvV5YLzVHuAR4KjRhXiJCuDfwNdcuOtpRUUF67x9UcdTR8/b/6UqmgZhAbl0bfwWva78B40iV+LvU4hjO/kqAn2P0zr2O25t8Sit6v1XwotwqJhgaB1vdBXCmRx+C8mbZQDDgE8BmUfJeRT6ZHUvANXprbF+/XqUUmjeel+iKBtKL72ruUmz0iAik4TwDeSfSmL7kX7sN3eisDQBq/K7jEIUJq2cyMD9NIz4jRZ15xAZmI2meWQjsDCYr48eYH7eZnQlwlkkwDiQAn5EQowzKWAR8A+qvyr49u3bKS0ttetj5VXMu8Fy+R1zTZqFOsG76NzwXcosoRw50YLDxW3IKbqawtIGnCqPwnI60ChlApQtlPiaSgn0LSAyMJv4sN+JC/2dOiE78DOdlH4uwulkJJJnkwDjBJUh5jOgjsG1eBIFLAaGcv5Ou1XJysri8OHDJCV56bCEvMyLH1MNmgYBvsU0iFhL/fC1KOVDhQqguDSWChUAwMmyOpi0CgL9CgDwM50ixP8IvqYSNKwSWkStSo7TF3gsNmpgnXAqCTBOcmZLTAzSsbemKoD/AM8DVS8mcX4FBQX8/vvv3hlglIKSfIe/rKaBplnw5yTRwXv+3BHi8LcS4rLFhenbLgkwHkk68TrRj8Bf0ddMkrv8l68cvcPuCC49vIC+vMW6deu8c0ZeSwkc2WB0FUIYIjQA4pw/KbswiAQYJ6rsE9MP+A3XXTLPVSmgEBgFPEf1+7xUJSMjA4vFCyeEsJRCuUzkJ7yTrwnaNTC6CuEsEmBqwTb0EPMB+g9hL2wHuGQK2AncDUymZuEFYMOGDRw6dKjGdbmdE4fhhBeetxDotzqbxBhdhXAWCTC15DjwJPAwsBcJMRdSCnwJ9ATm45jP6ujRo146H4xCrjbhza6sK30QPZUEmFpUAXwB3Ax8Q/XmMPEmCtiN3m/oQfSg5yhWq5Vff/3V+/rBmP/QZ+IVwkslRkJIgNFVCGeQAGOA3cAD6D+kNyO/HyugiD/D3dfoywQ42uLFi71vYceTeaC8sO+PEKfFhECgjLf1SBJgDFKGfpukB/Ay+ugabwsyCv1zWA70Qh92vueCz6iZXbt2sW9f9afUF0K4v9AAiA0zugrhDBJgDHYYPcD0AD5HX13Z04OMQh8avQK4F+iDPkqrwsnvW1xczMKFC73vNpIQXizEH+p68WL0nkwCjIvYhN7B9ybgPWA/nhdkFHCKP4NLL/QVvE/WYg2zZ8+mvLy8Ft/RQErB0Y1GVyGE4XzlJ51Hki+rC7EA69FHK3VBX6xwA/ptFncOMwrIRV+A8Wb04PI/aje4VMrMzGT37t0GvLNBTsn66MK7mTRon2h0FcIZJMC4qGxgHHADcDvwLXAQPeS4AwWYgaXA0+iBbAiwEmOCSyWz2cwvv/xiYAVCiNqkaRB4OYunC5cnAcbFmYGfgcHAtcAg9CHYe9CHYbtSy4wFvaVlKXpouQ59Lpd3gF24TviaPXs2ZWUytFgIIdyZDC5zE1b0Dr/fAf8FIoFm6J1/OwItgXjAj9pJpQo9kOQDB4A16KOJVqCPqHLleJCZmckff/xBixYtjC5FCFELZCI7zyQBxg1Z0YPDqtObCYgArgBan96uAhKAuqf3+Z9+ronq/2dWp99Loc8kXIE+vf8B9E7HG0//eQxjbwtdKrPZzPz582nevDmaJt/ahPB019TX+8JYXanJWtSYBBgPYEUPGGtOb6CHlBAgCGgMhJ3+dzuq30JTAPyO3tKyC/2WlRk9yLj794H//Oc/PPjgg4SEhBhdihDCycIDja5AOIMEGA+lgOLT25EzHv/RmHJczpYtW/jtt9+4+eabjS7FucIaGl2BEEI4hXTiFV6ptLSU77//3rMntdM0iLzC6CqEEMIpJMAIrzV37lwOHDhgdBlCCCEugwQY4bWys7P53//+59mtMEII4aEkwAiv9uWXX3r2CtXhjcEks3gJITyPBBjh1bZs2UJ6errntsKExIFJ+uoLITyPBBjh1UpKSnjvvfc8d2ZezUffhPBivx+SOWA8kQQY4fUWL15MZmam0WU4R0gChNY3ugohDFVwyugKhDNIgBFer6SkhP/85z9YLK6yWpMDmXzB5H/x44QQws1IgBEC+O6779i6davRZTieTwDUvdroKoQQwuEkwAgBHD9+nA8++MDzWmE0EwREG12FEIaxWmFHntFVCGeQACPEad999x3btm0zugzHi73W6AqEMIwCDhcaXYVwBgkwQpx2/Phx3n//fc9rhQlvLP1ghNeyKKiwGl2FcAYJMEKcYcaMGZ7XChNaH3yDjK5CCEPkn4CdRy5+nHA/EmCEOEN+fj7jxo2jtLTU6FIcJzgOwhsZXYUQhqiwQrmHNaoKnQQYIc4yc+ZMVqxY4Tmz8/oGQExLo6sQwhDb88BcYnQVwhkkwAhxlpKSEt5++21OnjxpdCmOoflATCujqxDCEAUn9ZFIwvNIgBGiCr/88gszZszwnFaY+OtkUUfhldbu10ciCc8jAUaIKlgsFl599VUOHTpkdCmOEZ0MwbFGVyFErbIqOFJsdBXCWSTACHEee/bs4a233vKMYdWB0VCntdFVCFGryiyw0UN+BxHnkgAjxHkopZg2bRqrV692/1tJmg8kdDG6CiFq1ZEi+OOY0VUIZ3F4gLFYLLz44oskJSURFBRE06ZNefXVV+1+ACilGDt2LPHx8QQFBZGWlsbOnTvtXic/P5/BgwcTHh5OZGQkw4YNo7hY2gJF7SooKOCVV17h1Ck3X85W0yC+s/SDEV5lxxEolBFIHsvhAebNN99k8uTJvP/++2zbto0333yTCRMm8O9//9t2zIQJE5g0aRJTpkwhIyODkJAQevbsSUnJn1fa4MGD2bJlCwsWLGDOnDksX76chx9+2NHlCnFRCxYsYOrUqe7fChN9FQTXM7oKIWrN1hyZhdeTacrB35VvueUWYmNj+fTTT22PDRgwgKCgIL788kuUUiQkJPDUU0/x9NNPA2A2m4mNjWXq1KkMHDiQbdu2kZyczJo1a+jQoQMA8+bNo0+fPhw4cICEhISL1lFYWEhERIQjT014sYSEBH755RdatnTj+VSsFpg3CHZ+Z3QlQjidVcFD0+GzDKMrEZfLbDYTHh5+3v0Ob4G57rrrWLRoETt27ADg999/Z8WKFfTu3RvQO0bm5OSQlpZme05ERAQpKSmkp6cDkJ6eTmRkpC28AKSlpWEymcjIqPpqLC0tpbCw0G4TwlEOHTrEc889595zw5h8oP71RlchRK04Va4PoRaey+EB5tlnn2XgwIG0aNECPz8/2rZty6hRoxg8eDAAOTk5AMTG2g/pjI2Nte3LycmhXj37pm5fX1+io6Ntx5xt/PjxRERE2LbExERHn5rwcnPnzmXatGlY3XlWrMSbwF9aJoXnyz4uHXg9ncMDzHfffcdXX33F119/zbp165g2bRr/+te/mDZtmqPfys6YMWMwm822bf9+id7CsSoqKnjhhRfce1RSRBOI7XDx44Rwc2uzodiDljQT53J4gHnmmWdsrTCtW7dmyJAhPPHEE4wfPx6AuLg4AHJzc+2el5uba9sXFxdHXl6e3f6Kigry8/Ntx5wtICCA8PBwu00IR8vPz2f06NEcO+amv9qZ/KDJbYBmdCVCOI3FCvO2G12FcDaHB5iTJ09iMtm/rI+Pj63ZPSkpibi4OBYtWmTbX1hYSEZGBqmpqQCkpqZSUFBAZmam7ZjFixdjtVpJSUlxdMlCXJJff/2VcePGUVFRYXQpl07ToOHN4C8BX3iuohJYvc/oKoSzOTzA9OvXj9dff52ffvqJvXv3MnPmTN555x3uuOMOADRNY9SoUbz22mvMnj2bTZs2MXToUBISErj99tsBuOqqq+jVqxcPPfQQq1evZuXKlYwcOZKBAwdWawSSEM6klOKTTz5h9uzZ7tkfJqIJ1O9qdBVCOM36g3ofGOHZHD6MuqioiBdffJGZM2eSl5dHQkIC9957L2PHjsXf3x/QfwC89NJLfPzxxxQUFNClSxc+/PBDmjVrZnud/Px8Ro4cyY8//ojJZGLAgAFMmjSJ0NDQatUhw6iFs8XHxzN//nxatWqFprnRLRmlYMd0mP8XUG4YwIS4AKXg9QXw4lyjKxE1dbFh1A4PMK5CAoyoDV27duWHH34gOjra6FIuTfEh+O46KJJ2duFZTpVD9w8gfa/RlYiaqvV5YITwJitWrODJJ5+ktNTNhjuExEPSLUZXIYTDZeXBJlnA0StIgBGiBpRSfPPNN0ycONG9Vq3WNLhqKPgGGV2JEA6jFMzdCsVlRlciaoMEGCFqqKysjPHjxzNv3jz3mh+mztUQl2p0FUI4zMkymL3Z6CpEbZEAI4QDFBQU8Ne//pWVK1e6T4jxDYTm94Im3waEZ1idDesPGF2FqC3ynUsIB8nLy+Pxxx9n165d7hNirhgAMa2MrkKIGrMq+GETlLnRnVxRMxJghHCg9evXM2jQIA4dcpNehAGRcOVdRlchRI3lFcHMjUZXIWqTBBghHGzt2rWMHj3aPVZE1zRo8RcIqW90JUJcNqXgxy1w0Gx0JaI2SYARwgm+/vprHnvsMfcIMWENIfl+o6sQ4rKVVMDXmfptJOE9JMAI4QRKKb744gtGjhzp+iFGM0GrB6UVRritjYf0DrzCu0iAEcJJlFJ8+eWX7tESI60wwk1VWOD95foQauFdJMAI4URuE2JsrTCyWKpwL5sOwyyZ+8UrSYARwsmsVitffvkljz/+uGuHmLCG0PYJmRdGuA2rghkboMjNVvIQjiHfqYSoBVarlS+++MK1Q4xmgpZ/heiWRlciRLXsy4dpa4yuQhhFAowQtcQtQkxAFLQdBSY/oysR4oKsCv5vFRySodNeSwKMELWoMsQMHTqUP/74w/Vm7NU0fXmBBjcYXYkQF7Q1Bz7PMLoKYSQJMELUMqvVyqxZsxg4cKBrhhifQEh9DfwjjK5EiCpVWGHCIjjsog2ZonZIgBHCIGvWrKFv374sXLjQtUKMpkG99tDqIaMrEeIcSsGGAzLySEiAEcJQWVlZDB06lFmzZlFeXm50OX8y+UD7Z6DO1UZXIoSdkgp4bQEUlhhdiTCaBBghDJaTk8OgQYN4++23KS4uNrqcPwXVhWufB58AoysRAji95tFm+Hmr0ZUIVyABRggXcOrUKV544QWGDx/O4cOHXeOWkqZB09v0Tr1CuICjJ+CV+VBmMboS4QokwAjhIiwWC19//TX9+vVj06ZNrhFifAIg5Z8Q2czoSoSXsyp4d6k++kgIkAAjhEtRSpGZmUnPnj35+uuvXaNfTFhDuOHf4BdqdCXCSykF6/bDJ+ngArFeuAgJMEK4oJycHIYNG8YzzzxDbm6usa0xmgaJ3eHqR0HzMa4O4bWKSmH0j/otJCEqSYARwkWVlpYyadIkevfuzapVq7BarcYVY/KBjs9DgxuNq0F4JauCyStg6S6jKxGuRgKMEC5MKcX69eu55ZZbGDduHAUFBca1xviFwQ2TIKyRMe8vvE7lraN/LdGDjBBnkgAjhBvIz8/npZde4rbbbiMjI8OY1hhNg6gW0PVf4BtS++8vvM7RE/D3mXLrSFRNAowQbsJqtbJ8+XL69u3L+PHjyc/Pr/3WGE2Dpnfot5M0+fYhnKfcAv+cB+l7jK5EuCr5DiSEm8nPz2fs2LGkpaXxyy+/UFFRUbsFmHzgmseg5TBAq933Fl5BKfhyLXyWIaOOxPlJgBHCDVmtVtavX8+dd97J8OHD2bt3b+22xviFwnXjIP662ntP4RWUgnUH4MW5UOICswgI1yUBRgg3VlxczKeffkq3bt1qv5NvYAz0+kLvFyOEgxwuhFEz4aDZ6EqEq5MAI4QH2L9/P2PHjuWmm25i6tSpnDhxwvlBRtMgrDHc+AGEJDj3vYRXOFkGz/8EK/4wuhLhDiTACOEhKm8rPfTQQ9x5550sXLiQ0tJS5wYZTdPnhun5BYTEO+99hMezWOHl+fDFWqMrEe5CAowQHsZisTBv3jxuvfVW+vfv7/wgUxlibpoCvsHOeQ/h0SxWvdPuh7/qfxeiOiTACOGhSkpKmDt3LrfeeisDBgxg0aJFlJaWOufNNA0a94HrXgOfQOe8h/BIleHlsf9BcZnR1Qh3oimXWPLW8QoLC4mIiDC6DCFcRmBgIN27d+eBBx4gLS2N8PBwNM3Bw6CtFfD7v2Hlc2ApcexrC4+jFKzcA/0+gYJTRlcjXI3ZbCY8PPy8+yXACOFlfHx8aNOmDX/729/o06cP9evXd2yQsVbAhknw2/MSYsR5KQWZ+2Hgf2D3UaOrEa5IAowQokqappGYmMjdd9/NoEGDSE5Oxt/f3zFhxloBG/4NGf+EssKav57wKEpB5gEYOE3Cizg/CTBCiIsKDQ2lc+fODBw4kO7du1O/fn1Mphp2kbNaYP9C+OUBOHnYMYUKt1cZXu6dBrskvIgLkAAjhKg2TdNo0KABPXv25LbbbqNTp07ExMRcfquMUrB/EcwfAidzHFuscDuVs+wOlPAiqkECjBDisvj6+pKYmMidd95Jt27dSElJsYWZSwo0SsHBZbDsCTi6wWn1CtdmtcKKPTDsGwkvonouFmAuuY14+fLl9OvXj4SEBDRN44cffrDbr5Ri7NixxMfHExQURFpaGjt37rQ7Jj8/n8GDBxMeHk5kZCTDhg2juLjY7piNGzfStWtXAgMDSUxMZMKECZdaqhCiBioqKtizZw9vvfUWd9xxBykpKQwfPpxvv/2W7OxsysrKqje3jKZB/evhlv9BXCdkAUjvY7XCV5lw2/9JeBGOc8kB5sSJE7Rp04YPPvigyv0TJkxg0qRJTJkyhYyMDEJCQujZsyclJX+ORhg8eDBbtmxhwYIFzJkzh+XLl/Pwww/b9hcWFtKjRw8aNWpEZmYmb731Fv/85z/5+OOPL+MUhRA1VRlmPvnkEwYNGsS1115Lz549+de//sWKFSs4cuTIhVfF1jQIT4J+P0Dy/aD51FbpwmClFTBtDYz8nwyVFo5Vo1tImqYxc+ZMbr/9dkBvfUlISOCpp57i6aefBvQmoNjYWKZOncrAgQPZtm0bycnJrFmzhg4dOgAwb948+vTpw4EDB0hISGDy5Mk8//zz5OTk4O/vD8Czzz7LDz/8wPbt26tVm9xCEqJ2BAQEEB8fT5s2bejSpQutW7fmqquuom7dugQEBJzbGbj8BGz6CNJfhIqTxhQtnE4pOFWuryr9/q9QZjG6IuFuLnYLydeRb7Znzx5ycnJIS0uzPRYREUFKSgrp6ekMHDiQ9PR0IiMjbeEFIC0tDZPJREZGBnfccQfp6el069bNFl4AevbsyZtvvsnx48eJiopyZNlCiBooLS1l79697N27l1mzZuHj40N4eDhJSUkkJyfTunVr2rVrR/PmzQkLCyMsLAytzWOYoprB0sehcI/RpyAcTCl9VelHZ8CcrbI8gHAOhwaYnBx9lEFsbKzd47GxsbZ9OTk51KtXz74IX1+io6PtjklKSjrnNSr3VRVgSktL7aZJLyyUuSeEMILFYuH48eMcP36cdevWAfrkeREREdStW5f69etz5ZVXkpCQQFL0UJKPTeaaqDx8ZGETj6AUrN4Hj8yA9QeNrkZ4MocGGCONHz+el19+2egyhBBVsFgs5Ofnk5+fT1ZWFosXLwb029Ah/op/3ASPdYOIQL27jHBPZRb4JhOe/wkOmo2uRng6h/7OExcXB0Bubq7d47m5ubZ9cXFx5OXl2e2vqKggPz/f7piqXuPM9zjbmDFjMJvNtm3//v01PyEhhFMppSguhX/Ogzs+ha05+m/wwr0opQeWR2fA8BkSXkTtcGiASUpKIi4ujkWLFtkeKywsJCMjg9TUVABSU1MpKCggMzPTdszixYuxWq2kpKTYjlm+fDnl5eW2YxYsWEDz5s3P2/8lICCA8PBwu00I4R6sCpbugh5TYMpKOCGrErsNixWW7NSHSH+6CkrKL/4cIRzhkgNMcXExGzZsYMOGDYDecXfDhg1kZ2ejaRqjRo3itddeY/bs2WzatImhQ4eSkJBgG6l01VVX0atXLx566CFWr17NypUrGTlyJAMHDiQhIQGAQYMG4e/vz7Bhw9iyZQvffvstEydO5Mknn3TYiQshXM8hMzz+vT7N/Kq9+vwhwjUpBUeL9dtFt3+qL8woRG265GHUS5cu5cYbbzzn8fvuu4+pU6eilOKll17i448/pqCggC5duvDhhx/SrFkz27H5+fmMHDmSH3/8EZPJxIABA5g0aRKhoaG2YzZu3MiIESNYs2YNderU4bHHHmP06NHVrlOGUQvh3qKD4Ykb4OFUqBsqfWNcSYUVlu+GZ3+Etfvltp9wDllKQAjhtjSgTX14oQf0awn+HjPswD0pBQfMMGkZfPQbFJVe/DlCXC4JMEIItxfgA7e1hlHXw7UNwVcm8q1VSulh5au1MHE5ZOVd/DlC1JQEGCGExwj1h792gse7QVIMmOS2klMpBSUVsHgH/GuJftvI6pE/MYQrkgAjhPA4cWEw5Fp4+DpoIkHGKSqs8PtBGLcA5myRpQBE7ZMAI4TwWHFhMPR0kJEWGceosMLGg/DvX2HmRjCXXPw5QjiDBBghhMeLC4NbW8EDKdA+Efykj8wlqbxVtPIP+DJTDy6FElyEwSTACCG8RmgA9GwBg9tDj+YQ7C/Dry9EKTh+ChbtgI9/0/u4yK0i4SokwAghvI6fCa6urweZPsl6PxlpldEppd8m2nccvlsP09fBlhzpnCtcjwQYIYRXiwyC7s3grjbQtSnEhul9ZbypZUYpUMCRYvj1D/g8Q5/pOP+k0ZUJcX4SYIQQAj20xIdDt6Zwe2vo0sSzw8yZoeW3PTBrEyzZBQcLwOKR3/WFp5EAI4QQZzFpEBcOHRtCWnPo1gSa1oEgP/cOM0pBqQUOFegtLYt3wtKd+urQElqEu5EAI4QQF6Chd/ZNjoPrGuu3mVrGQYNI/XFXHpqtlN7p9nChPmfLr39A+l59ptz8E3oLjBDuSgKMEEJcApOmt8Q0iob2DaBtAz3cXFFHX1QyyA98TbXfUmOxQrkFcov0bWsOZGTrc7ZkHYGCk9LKIjyLBBghhKghX5MeXBIj9X4zrROgfgQ0rwdRwZAUDWj6Ctr+p0c7aRr4VKN/jcVqPwKo4BSUlOvDm/cc0zva/n5I77uy+6g+euhkmT5vixCezGsDjNlsJjIy0ugyhBAezs90er4ZTt92CtAfD/bVV9K+2C2ovflwsPD0PxQcKoSiEr215WS5EwsXwsUVFBRcsCHCYxenP3bsmNElCCG8QLn1z+n2C3Ls9y3dXfv1COEpioqKvDPAREdHA5Cdne21t5IKCwtJTExk//79F2yG81Tefv4gn4G3nz/IZ+Dt5w/u9xkopSgqKiIhIeGCx3lsgDGZTABERES4xRfMmcLDw736M/D28wf5DLz9/EE+A28/f3Cvz6A6DQ+mWqhDCCGEEMKhJMAIIYQQwu14bIAJCAjgpZdeIiAgwOhSDOPtn4G3nz/IZ+Dt5w/yGXj7+YPnfgYeO4xaCCGEEJ7LY1tghBBCCOG5JMAIIYQQwu1IgBFCCCGE25EAI4QQQgi345EB5oMPPqBx48YEBgaSkpLC6tWrjS7JIcaPH8+1115LWFgY9erV4/bbbycrK8vumBtuuAFN0+y24cOH2x2TnZ1N3759CQ4Opl69ejzzzDNUVLjHynD//Oc/zzm/Fi1a2PaXlJQwYsQIYmJiCA0NZcCAAeTm5tq9hjufP0Djxo3P+Qw0TWPEiBGA510Dy5cvp1+/fiQkJKBpGj/88IPdfqUUY8eOJT4+nqCgINLS0ti5c6fdMfn5+QwePJjw8HAiIyMZNmwYxcXFdsds3LiRrl27EhgYSGJiIhMmTHD2qVXbhT6D8vJyRo8eTevWrQkJCSEhIYGhQ4dy6NAhu9eo6rp544037I5x1c/gYtfA/ffff8659erVy+4YT74GgCq/J2iaxltvvWU7xp2vgSopDzN9+nTl7++vPvvsM7Vlyxb10EMPqcjISJWbm2t0aTXWs2dP9fnnn6vNmzerDRs2qD59+qiGDRuq4uJi2zHXX3+9euihh9Thw4dtm9lstu2vqKhQrVq1UmlpaWr9+vVq7ty5qk6dOmrMmDFGnNIle+mll1TLli3tzu/IkSO2/cOHD1eJiYlq0aJFau3atapTp07quuuus+139/NXSqm8vDy781+wYIEC1JIlS5RSnncNzJ07Vz3//PPq+++/V4CaOXOm3f433nhDRUREqB9++EH9/vvv6tZbb1VJSUnq1KlTtmN69eql2rRpo1atWqV+/fVXdcUVV6h7773Xtt9sNqvY2Fg1ePBgtXnzZvXNN9+ooKAg9dFHH9XWaV7QhT6DgoIClZaWpr799lu1fft2lZ6erjp27Kjat29v9xqNGjVSr7zyit11ceb3Dlf+DC52Ddx3332qV69edueWn59vd4wnXwNKKbtzP3z4sPrss8+Upmlq9+7dtmPc+RqoiscFmI4dO6oRI0bY/m2xWFRCQoIaP368gVU5R15engLUsmXLbI9df/316u9///t5nzN37lxlMplUTk6O7bHJkyer8PBwVVpa6sxyHeKll15Sbdq0qXJfQUGB8vPzUzNmzLA9tm3bNgWo9PR0pZT7n39V/v73v6umTZsqq9WqlPLsa+Dsb9xWq1XFxcWpt956y/ZYQUGBCggIUN98841SSqmtW7cqQK1Zs8Z2zM8//6w0TVMHDx5USin14YcfqqioKLvzHz16tGrevLmTz+jSVfXD62yrV69WgNq3b5/tsUaNGql33333vM9xl8/gfAHmtttuO+9zvPEauO2229RNN91k95inXAOVPOoWUllZGZmZmaSlpdkeM5lMpKWlkZ6ebmBlzmE2m4E/F66s9NVXX1GnTh1atWrFmDFjOHnypG1feno6rVu3JjY21vZYz549KSwsZMuWLbVTeA3t3LmThIQEmjRpwuDBg8nOzgYgMzOT8vJyu69/ixYtaNiwoe3r7wnnf6aysjK+/PJL/vrXv6Jpmu1xT78GKu3Zs4ecnBy7r3lERAQpKSl2X/PIyEg6dOhgOyYtLQ2TyURGRobtmG7duuHv7287pmfPnmRlZXH8+PFaOhvHMZvNaJpGZGSk3eNvvPEGMTExtG3blrfeesvutqG7fwZLly6lXr16NG/enEceeYRjx47Z9nnbNZCbm8tPP/3EsGHDztnnSdeARy3mePToUSwWi903ZoDY2Fi2b99uUFXOYbVaGTVqFJ07d6ZVq1a2xwcNGkSjRo1ISEhg48aNjB49mqysLL7//nsAcnJyqvx8Kve5upSUFKZOnUrz5s05fPgwL7/8Ml27dmXz5s3k5OTg7+9/zjft2NhY27m5+/mf7YcffqCgoID777/f9pinXwNnqqy3qvM582ter149u/2+vr5ER0fbHZOUlHTOa1Tui4qKckr9zlBSUsLo0aO599577Rbue/zxx2nXrh3R0dH89ttvjBkzhsOHD/POO+8A7v0Z9OrVi/79+5OUlMTu3bt57rnn6N27N+np6fj4+HjdNTBt2jTCwsLo37+/3eOedg14VIDxJiNGjGDz5s2sWLHC7vGHH37Y9vfWrVsTHx9P9+7d2b17N02bNq3tMh2ud+/etr9fffXVpKSk0KhRI7777juCgoIMrMwYn376Kb1797Zbdt7TrwFxfuXl5dx9990opZg8ebLdvieffNL296uvvhp/f3/+9re/MX78eLefYn7gwIG2v7du3Zqrr76apk2bsnTpUrp3725gZcb47LPPGDx4MIGBgXaPe9o14FG3kOrUqYOPj885o05yc3OJi4szqCrHGzlyJHPmzGHJkiU0aNDggsempKQAsGvXLgDi4uKq/Hwq97mbyMhImjVrxq5du4iLi6OsrIyCggK7Y878+nvS+e/bt4+FCxfy4IMPXvA4T74GKuu90P/5uLg48vLy7PZXVFSQn5/vUddFZXjZt28fCxYssGt9qUpKSgoVFRXs3bsX8IzPoFKTJk2oU6eO3TXvDdcAwK+//kpWVtZFvy+A+18DHhVg/P39ad++PYsWLbI9ZrVaWbRoEampqQZW5hhKKUaOHMnMmTNZvHjxOU19VdmwYQMA8fHxAKSmprJp0ya7/8yV3+ySk5OdUrczFRcXs3v3buLj42nfvj1+fn52X/+srCyys7NtX39POv/PP/+cevXq0bdv3wse58nXQFJSEnFxcXZf88LCQjIyMuy+5gUFBWRmZtqOWbx4MVar1RbuUlNTWb58OeXl5bZjFixYQPPmzV2u2bwqleFl586dLFy4kJiYmIs+Z8OGDZhMJtutFXf/DM504MABjh07ZnfNe/o1UOnTTz+lffv2tGnT5qLHuv01YHQvYkebPn26CggIUFOnTlVbt25VDz/8sIqMjLQbceGuHnnkERUREaGWLl1qNwzu5MmTSimldu3apV555RW1du1atWfPHjVr1izVpEkT1a1bN9trVA6h7dGjh9qwYYOaN2+eqlu3rssOoT3bU089pZYuXar27NmjVq5cqdLS0lSdOnVUXl6eUkofRt2wYUO1ePFitXbtWpWamqpSU1Ntz3f3869ksVhUw4YN1ejRo+0e98RroKioSK1fv16tX79eAeqdd95R69evt42weeONN1RkZKSaNWuW2rhxo7rtttuqHEbdtm1blZGRoVasWKGuvPJKuyG0BQUFKjY2Vg0ZMkRt3rxZTZ8+XQUHB7vM8NELfQZlZWXq1ltvVQ0aNFAbNmyw+95QOZrkt99+U++++67asGGD2r17t/ryyy9V3bp11dChQ23v4cqfwYXOv6ioSD399NMqPT1d7dmzRy1cuFC1a9dOXXnllaqkpMT2Gp58DVQym80qODhYTZ48+Zznu/s1UBWPCzBKKfXvf/9bNWzYUPn7+6uOHTuqVatWGV2SQwBVbp9//rlSSqns7GzVrVs3FR0drQICAtQVV1yhnnnmGbs5QJRSau/evap3794qKChI1alTRz311FOqvLzcgDO6dPfcc4+Kj49X/v7+qn79+uqee+5Ru3btsu0/deqUevTRR1VUVJQKDg5Wd9xxhzp8+LDda7jz+VeaP3++AlRWVpbd4554DSxZsqTK6/6+++5TSulDqV988UUVGxurAgICVPfu3c/5XI4dO6buvfdeFRoaqsLDw9UDDzygioqK7I75/fffVZcuXVRAQICqX7++euONN2rrFC/qQp/Bnj17zvu9oXJuoMzMTJWSkqIiIiJUYGCguuqqq9S4cePsfsAr5bqfwYXO/+TJk6pHjx6qbt26ys/PTzVq1Eg99NBD5/zS6snXQKWPPvpIBQUFqYKCgnOe7+7XQFU0pZRyahOPEEIIIYSDeVQfGCGEEEJ4BwkwQgghhHA7EmCEEEII4XYkwAghhBDC7UiAEUIIIYTbkQAjhBBCCLcjAUYIIYQQbkcCjBBCCCHcjgQYIYQQQrgdCTBCCCGEcDsSYIQQQgjhdiTACCGEEMLt/D8RvRRPnRWMQQAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T18:00:52.637886Z",
     "start_time": "2024-06-23T18:00:52.295214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def plot_vectors_with_z_value_as_color(vectors, foreground_mask, clim, cmap):\n",
    "    pcd_pv = pv.PolyData(vectors[foreground_mask].numpy())\n",
    "    pcd_pv['point_color'] = pcd_pv.points[:, 2] # use z values as color\n",
    "    plotter = pv.Plotter()\n",
    "    plotter.add_mesh(pcd_pv,\n",
    "            scalars='point_color',\n",
    "            clim=clim,\n",
    "            cmap=cmap)\n",
    "    return plotter\n",
    "\n",
    "plotter = plot_vectors_with_z_value_as_color(points_hit, foreground_mask_with_0, clim=[6,16], cmap='terrain')\n",
    "plotter.show()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:58248/index.html?ui=P_0x12c968620_0&reconnect=auto\" class=\"pyvista…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "850752ac7aa84118860ce60d0ad02a7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T18:00:58.194952Z",
     "start_time": "2024-06-23T18:00:57.989420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_vectors_with_magnitude_as_color(vectors, foreground_mask, clim, cmap):\n",
    "    pcd_pv = pv.PolyData(vectors[foreground_mask].numpy())\n",
    "    pcd_pv['point_color'] = torch.norm(vectors[foreground_mask], p=2, dim=1, keepdim=True).numpy()\n",
    "    plotter = pv.Plotter()\n",
    "    plotter.add_mesh(pcd_pv,\n",
    "        scalars='point_color',\n",
    "        clim=clim,\n",
    "        cmap=cmap)\n",
    "    return plotter\n",
    "\n",
    "plotter = plot_vectors_with_magnitude_as_color(surface_normals_hit, foreground_mask_with_0, clim=[0,12], cmap='terrain')\n",
    "plotter.show()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:58248/index.html?ui=P_0x12f5dce30_1&reconnect=auto\" class=\"pyvista…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6e6e0ec130647388c600fd0a13ecf45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
